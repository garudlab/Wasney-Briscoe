{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal packages\n",
    "import os\n",
    "import sys\n",
    "import lz4.frame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(\"/u/project/ngarud/michaelw/Diversity-Along-Gut/ConventionalMouse/scripts/postprocessing/postprocessing_scripts/\")\n",
    "import config\n",
    "\n",
    "# Statistical packages\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# custom\n",
    "import diversity_utils\n",
    "import species_utils\n",
    "import parse_midas_data\n",
    "import calculate_intersample_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing QP stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load species list\n",
    "species_list_path = \"%sspecies_snps.txt\" % (config.metadata_directory)\n",
    "\n",
    "with open(species_list_path, \"r\") as f:\n",
    "    species_list = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "species_code_map = species_utils.parse_species_code_maps()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = np.loadtxt(config.accessions, comments = \"#\", dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp_array = []\n",
    "for species in species_list:\n",
    "    highcoverage_samples = diversity_utils.calculate_highcoverage_samples(species)\n",
    "    if len(highcoverage_samples) == 0:\n",
    "        continue\n",
    "    haploid_samples = diversity_utils.calculate_haploid_samples(species, quick_and_dirty=True) #  quick_and_dirty=True\n",
    "    non_haploid_samples = [s for s in highcoverage_samples if s not in set(haploid_samples)]\n",
    "    number_of_haploid_samples = len(haploid_samples)\n",
    "    number_of_non_haploid_samples = len(non_haploid_samples)\n",
    "    qp_array.append([species, number_of_haploid_samples, \"QP\"])\n",
    "    qp_array.append([species, number_of_non_haploid_samples, \"Not QP\"])\n",
    "qp_df = pd.DataFrame(data = qp_array, columns = [\"species\", \"sample_count\", \"QP\"])\n",
    "qp_df['sample_count'] = qp_df[\"sample_count\"].astype(float)\n",
    "qp_df['species_name'] = [species_code_map[species] for species in qp_df['species']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>sample_count</th>\n",
       "      <th>QP</th>\n",
       "      <th>species_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>207693</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>f__Oscillospiraceae (207693)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100555</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__Lawsonibacter (100555)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>214603</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__CAG-95 (214603)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>203686</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__UBA3282 (203686)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>261672</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__Angelakisella (261672)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>217378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__1XD42-69 (217378)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>229722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__Ruminiclostridium_E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>231109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__CAG-81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>231118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__Clostridium_Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>266763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not QP</td>\n",
       "      <td>g__Eubacterium_F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species  sample_count      QP                  species_name\n",
       "33   207693           6.0  Not QP  f__Oscillospiraceae (207693)\n",
       "11   100555           4.0  Not QP     g__Lawsonibacter (100555)\n",
       "51   214603           4.0  Not QP            g__CAG-95 (214603)\n",
       "17   203686           4.0  Not QP           g__UBA3282 (203686)\n",
       "97   261672           2.0  Not QP     g__Angelakisella (261672)\n",
       "..      ...           ...     ...                           ...\n",
       "63   217378           0.0  Not QP          g__1XD42-69 (217378)\n",
       "67   229722           0.0  Not QP        g__Ruminiclostridium_E\n",
       "69   231109           0.0  Not QP                     g__CAG-81\n",
       "71   231118           0.0  Not QP              g__Clostridium_Q\n",
       "127  266763           0.0  Not QP              g__Eubacterium_F\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp_df[qp_df[\"QP\"] == \"Not QP\"].sort_values(\"sample_count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "## species\n",
    "qp_df_species_total = pd.DataFrame(qp_df.groupby([\"species_name\"])['sample_count'].sum()).reset_index()\n",
    "qp_df_species_notqp = qp_df[qp_df[\"QP\"] == \"Not QP\"]\n",
    "\n",
    "## Order\n",
    "threshold = 2\n",
    "species_over_threshold = qp_df_species_total[qp_df_species_total['sample_count'] >= threshold].species_name.unique()\n",
    "qp_df_species_total = qp_df_species_total[qp_df_species_total.species_name.isin(species_over_threshold)]\n",
    "qp_df_species_notqp = qp_df_species_notqp[qp_df_species_notqp.species_name.isin(species_over_threshold)]\n",
    "species_order = qp_df_species_total.sort_values(by=\"sample_count\", ascending=False)[\"species_name\"].tolist()\n",
    "\n",
    "## Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 14))  # Adjusted height for better vertical spacing\n",
    "\n",
    "sns.barplot(data=qp_df_species_total, y=\"species_name\", x=\"sample_count\", color=\"turquoise\", order=species_order, ax=ax)\n",
    "sns.barplot(data=qp_df_species_notqp, y=\"species_name\", x=\"sample_count\", color=\"purple\", order=species_order, ax=ax)\n",
    "\n",
    "qp_patch = mpatches.Patch(color=\"turquoise\", label=\"QP\")\n",
    "not_qp_patch = mpatches.Patch(color=\"purple\", label=\"Not QP\")\n",
    "ax.legend(handles=[qp_patch, not_qp_patch], title=\"QP status\")\n",
    "ax.set_xlabel(\"Number of Samples\", fontsize=14)   # change x-axis label\n",
    "ax.set_ylabel(\"Species\", fontsize=14)  \n",
    "\n",
    "plt.yticks(rotation=0)  # No need to rotate y-axis ticks\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/u/project/ngarud/michaelw/Diversity-Along-Gut/ConventionalMouse/figures/summary_stats/qp_samples.png\"\n",
    "fig.savefig(out_path, dpi = 300, facecolor = \"white\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCoA of species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_normalize = False\n",
    "\n",
    "if mean_normalize:\n",
    "\n",
    "    print(\"Mean normalizing features in the data set (i.e., each species has a mean of ~0 and a variance of 1)\")\n",
    "    \n",
    "    ## load data\n",
    "    species_relabs_path = \"%sspecies/species_relative_abundance.tsv\" % (config.data_directory)\n",
    "    species_relabs = pd.read_csv(species_relabs_path, sep = \"\\t\").set_index(\"species_id\")\n",
    "\n",
    "    ## Remove rows and column where all values are 0\n",
    "    species_relabs = species_relabs[~(species_relabs == 0).all(axis=1)] \n",
    "    species_relabs = species_relabs.loc[:,~(species_relabs == 0).all(axis=0)] \n",
    "\n",
    "    # Rotate df\n",
    "    species_relabs = species_relabs.T\n",
    "\n",
    "    ## mean normalization\n",
    "    species_relabs = (species_relabs - species_relabs.mean())/species_relabs.std()\n",
    "\n",
    "    ## numpy array format\n",
    "    samples = species_relabs.index\n",
    "    species = species_relabs.columns\n",
    "    species_relabs = np.array(species_relabs)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Using raw compositional data (i.e., L1 normalization, wherein features in a sample sum to 1)\")\n",
    "\n",
    "    ## load data\n",
    "    species_relabs_path = \"%sspecies/species_relative_abundance.tsv\" % (config.data_directory,)\n",
    "    species_relabs = pd.read_csv(species_relabs_path, sep = \"\\t\").set_index(\"species_id\")\n",
    "\n",
    "    ## Remove rows and column where all values are 0\n",
    "    species_relabs = species_relabs[~(species_relabs == 0).all(axis=1)] # Remove rows where all values are 0\n",
    "    species_relabs = species_relabs.loc[:,~(species_relabs == 0).all(axis=0)] \n",
    "\n",
    "    ## Rotate df\n",
    "    species_relabs = species_relabs.T\n",
    "    \n",
    "    ## numpy array format\n",
    "    samples = species_relabs.index\n",
    "    species = species_relabs.columns\n",
    "    species_relabs = np.array(species_relabs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances\n",
    "distances = pairwise_distances(species_relabs, metric='braycurtis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCoA using MDS\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "coordinates = mds.fit_transform(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "sample_metadata_map = parse_midas_data.parse_sample_metadata_map()\n",
    "# Configure as pandas dataframe\n",
    "mds_df = pd.DataFrame(coordinates)\n",
    "mds_df['samples'] = samples\n",
    "mds_df['mouse'] = mds_df['samples'].apply(lambda s: sample_metadata_map[s]['mouse'])\n",
    "mds_df['cage'] = mds_df['samples'].apply(lambda s: sample_metadata_map[s]['cage'])\n",
    "mds_df['location'] = mds_df['samples'].apply(lambda s: sample_metadata_map[s]['location'])\n",
    "mds_df['sex'] = mds_df['samples'].apply(lambda s: sample_metadata_map[s]['sex'])\n",
    "mds_df = mds_df.rename(columns = {0: \"MDS 1\", 1: \"MDS 2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data = mds_df, x = \"MDS 1\", y = \"MDS 2\", hue = \"cage\", ax = ax)\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), title=\"cage\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/u/project/ngarud/michaelw/Diversity-Along-Gut/ConventionalMouse/figures/summary_stats/PCoA_cage.png\"\n",
    "fig.savefig(out_path, dpi = 300, facecolor = \"white\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling evolutionary changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100042', '100110', '100111', '100113', '100118']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_list = species_utils.load_species_list()\n",
    "species_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "sample_metadata_map = parse_midas_data.parse_sample_metadata_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load species code maps\n",
    "species_code_map = species_utils.parse_species_code_maps()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing species 100042\n",
      "Species 100042 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 100110\n",
      "Species 100110 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 100111\n",
      "Species 100111 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 100113\n",
      "Species 100113 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 100118\n",
      "Species 100118 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 100158\n",
      "Species 100158 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 100171\n",
      "Species 100171 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 100320\n",
      "Species 100320 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 100334\n",
      "100334 has multiple haploid samples!\n",
      "Processing species 100338\n",
      "Species 100338 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 100375\n",
      "Species 100375 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 100395\n",
      "Species 100395 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 100500\n",
      "Species 100500 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 100555\n",
      "Species 100555 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 100600\n",
      "Species 100600 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 201916\n",
      "Species 201916 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 202897\n",
      "Species 202897 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 203686\n",
      "Species 203686 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 204195\n",
      "Species 204195 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 204380\n",
      "Species 204380 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 204699\n",
      "Species 204699 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 204819\n",
      "Species 204819 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 205132\n",
      "Species 205132 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 205142\n",
      "Species 205142 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 205224\n",
      "Species 205224 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 205270\n",
      "Species 205270 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 205567\n",
      "Species 205567 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 206400\n",
      "Species 206400 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 206896\n",
      "Species 206896 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 207450\n",
      "Species 207450 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 207550\n",
      "Species 207550 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 207693\n",
      "Species 207693 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 208232\n",
      "Species 208232 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 208519\n",
      "Species 208519 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 208766\n",
      "Species 208766 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 209106\n",
      "Species 209106 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 209838\n",
      "Species 209838 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 209914\n",
      "Species 209914 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 211235\n",
      "Species 211235 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 211853\n",
      "211853 has multiple haploid samples!\n",
      "Processing species 213184\n",
      "213184 has multiple haploid samples!\n",
      "Processing species 213583\n",
      "Species 213583 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 213942\n",
      "Species 213942 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 213999\n",
      "Species 213999 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 214603\n",
      "Species 214603 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 214845\n",
      "Species 214845 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 214912\n",
      "Species 214912 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 216392\n",
      "Species 216392 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 216453\n",
      "Species 216453 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 216689\n",
      "Species 216689 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 216954\n",
      "Species 216954 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 217094\n",
      "Species 217094 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 217240\n",
      "Species 217240 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 217253\n",
      "Species 217253 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 217378\n",
      "Species 217378 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 217610\n",
      "Species 217610 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 217744\n",
      "Species 217744 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 218434\n",
      "Species 218434 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 229275\n",
      "Species 229275 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 229547\n",
      "Species 229547 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 229633\n",
      "Species 229633 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 229722\n",
      "Species 229722 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 229914\n",
      "Species 229914 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 229998\n",
      "Species 229998 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 230525\n",
      "Species 230525 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 231066\n",
      "Species 231066 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 231109\n",
      "Species 231109 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 231118\n",
      "Species 231118 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 231258\n",
      "Species 231258 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 231349\n",
      "Species 231349 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 231504\n",
      "Species 231504 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 231887\n",
      "Species 231887 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 231977\n",
      "Species 231977 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 231995\n",
      "Species 231995 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 232356\n",
      "Species 232356 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 234341\n",
      "Species 234341 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 236627\n",
      "Species 236627 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 236833\n",
      "Species 236833 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 237711\n",
      "Species 237711 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 237892\n",
      "237892 has multiple haploid samples!\n",
      "Processing species 240066\n",
      "Species 240066 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 242035\n",
      "Species 242035 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 251524\n",
      "Species 251524 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 253991\n",
      "Species 253991 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 255975\n",
      "Species 255975 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 259253\n",
      "Species 259253 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 261649\n",
      "Species 261649 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 261672\n",
      "Species 261672 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 261676\n",
      "Species 261676 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 261755\n",
      "Species 261755 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 262018\n",
      "Species 262018 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 262170\n",
      "Species 262170 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 263040\n",
      "263040 has multiple haploid samples!\n",
      "Processing species 263303\n",
      "Species 263303 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 263323\n",
      "Species 263323 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 263490\n",
      "Species 263490 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 263510\n",
      "Species 263510 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 263558\n",
      "Species 263558 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 263672\n",
      "Species 263672 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 264045\n",
      "Species 264045 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 264289\n",
      "Species 264289 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 264316\n",
      "Species 264316 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 264450\n",
      "Species 264450 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 264455\n",
      "Species 264455 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 264501\n",
      "Species 264501 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 264599\n",
      "Species 264599 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 264624\n",
      "264624 has multiple haploid samples!\n",
      "Processing species 264714\n",
      "Species 264714 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 264958\n",
      "Species 264958 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 265025\n",
      "Species 265025 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 265132\n",
      "Species 265132 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 265152\n",
      "Species 265152 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 265282\n",
      "Species 265282 doesn't has less than 2 haploid samples. Skipping to next species\n",
      "Processing species 265345\n",
      "Species 265345 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 265440\n",
      "Species 265440 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 266183\n",
      "Species 266183 doesn't meet coverage requirements. Skipping to next species.\n",
      "Processing species 266763\n",
      "Species 266763 doesn't has less than 2 haploid samples. Skipping to next species\n"
     ]
    }
   ],
   "source": [
    "change_rate_array = []\n",
    "for species in species_list:\n",
    "    print(\"Processing species %s\" % (species))\n",
    "\n",
    "    highcoverage_samples = diversity_utils.calculate_highcoverage_samples(species)\n",
    "\n",
    "    if len(highcoverage_samples) == 0:\n",
    "        print(\"Species %s doesn't meet coverage requirements. Skipping to next species.\" % (species))\n",
    "        continue\n",
    "\n",
    "    haploid_samples = diversity_utils.calculate_haploid_samples(species, quick_and_dirty=True, quick_and_dirty_threshold = 1e-5)\n",
    "    \n",
    "    if len(haploid_samples) < 2:\n",
    "        print(\"Species %s doesn't has less than 2 haploid samples. Skipping to next species\" % (species))\n",
    "        continue\n",
    "\n",
    "    print(\"%s has multiple haploid samples!\" % (species))\n",
    "    \n",
    "    intersample_change_map = calculate_intersample_changes.load_intersample_change_map(species)\n",
    "    \n",
    "    pairs = list(intersample_change_map.keys())\n",
    "\n",
    "    for pair in pairs:\n",
    "        \n",
    "        opportunities = intersample_change_map[pair]['snps'][0]\n",
    "        changes = intersample_change_map[pair]['snps'][2]\n",
    "        number_of_changes = len(changes)\n",
    "        change_rate = number_of_changes/opportunities\n",
    "\n",
    "        change_rate_array.append([species, pair[0], pair[1], number_of_changes, opportunities, change_rate])\n",
    "\n",
    "change_rate_df = pd.DataFrame(data = change_rate_array, columns = [\"species\", \"sample_1\", \"sample_2\", \"number_of_changes\", \"opportunities\", \"change_rate\"])\n",
    "change_rate_df = change_rate_df.sort_values(by = \"number_of_changes\", ascending=False)\n",
    "\n",
    "# annotate\n",
    "## Mouse\n",
    "change_rate_df[\"mouse_1\"] = change_rate_df[\"sample_1\"].apply(lambda x: sample_metadata_map[x][\"mouse\"])\n",
    "change_rate_df[\"mouse_2\"] = change_rate_df[\"sample_2\"].apply(lambda x: sample_metadata_map[x][\"mouse\"])\n",
    "\n",
    "# cage\n",
    "change_rate_df[\"cage_1\"] = change_rate_df[\"sample_1\"].apply(lambda x: sample_metadata_map[x][\"cage\"])\n",
    "change_rate_df[\"cage_2\"] = change_rate_df[\"sample_2\"].apply(lambda x: sample_metadata_map[x][\"cage\"])\n",
    "\n",
    "# cage\n",
    "change_rate_df[\"location_1\"] = change_rate_df[\"sample_1\"].apply(lambda x: sample_metadata_map[x][\"location\"])\n",
    "change_rate_df[\"location_2\"] = change_rate_df[\"sample_2\"].apply(lambda x: sample_metadata_map[x][\"location\"])\n",
    "\n",
    "# Host orientation\n",
    "change_rate_df[\"orientation\"] = change_rate_df.apply(lambda row: \"Within host\" if ((row[\"mouse_1\"] == row[\"mouse_2\"]) & (row[\"cage_1\"] == row[\"cage_2\"])) else \"Between host\", axis = 1)\n",
    "\n",
    "# Coarse graining\n",
    "change_rate_df[\"coarse_location_1\"] = change_rate_df[\"location_1\"].apply(lambda x: \"Small intestine\" if x in [\"Duodenum\", \"Jejunum\", \"Ileum\"] else \"Large intestine\")\n",
    "change_rate_df[\"coarse_location_2\"] = change_rate_df[\"location_2\"].apply(lambda x: \"Small intestine\" if x in [\"Duodenum\", \"Jejunum\", \"Ileum\"] else \"Large intestine\")\n",
    "\n",
    "# Taxnomic assignment\n",
    "\n",
    "change_rate_df['taxonomic_assignment'] = change_rate_df[\"species\"].apply(lambda x: species_code_map[x])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/u/project/ngarud/michaelw/Diversity-Along-Gut/ConventionalMouse/tables/snp_change_rate_5e5.tsv\"\n",
    "change_rate_df.to_csv(out_path, sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_rate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired order for the 'orientation' column\n",
    "\n",
    "change_rate_df['orientation'] = pd.Categorical(\n",
    "    change_rate_df['orientation'],\n",
    "    categories=[\"Within host\", \"Between host\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Initialize subplots\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create the box plot\n",
    "sns.boxplot(\n",
    "    data=change_rate_df,\n",
    "    x=\"orientation\",\n",
    "    y=\"change_rate\",\n",
    "    ax=ax,\n",
    "    showfliers=False  # Optional: Hide outliers in the box plot\n",
    ")\n",
    "\n",
    "# Overlay scatter points\n",
    "sns.stripplot(\n",
    "    data=change_rate_df,\n",
    "    x=\"orientation\",\n",
    "    y=\"change_rate\",\n",
    "    hue=\"taxonomic_assignment\",\n",
    "    ax=ax,\n",
    "    dodge=False,  # Separate points by hue\n",
    "    palette=\"dark\",\n",
    "    alpha=0.7,  # Adjust transparency for better visualization\n",
    ")\n",
    "\n",
    "# Customize the legend\n",
    "ax.legend(\n",
    "    title=\"Taxonomic Assignment\",\n",
    "    loc=\"upper center\",  # Place the legend above the x-axis\n",
    "    bbox_to_anchor=(0.5, -0.15),  # Center the legend below the plot\n",
    "    ncol=2  # Set the legend to have two columns\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_ylabel(\"SNV change rate\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_title(\"Rate of SNV changes observed across conventional mouse samples.\")\n",
    "# ax.set_title(\"SNP change rate from 2mo to 6mo within hosts\")\n",
    "\n",
    "\n",
    "out_path = \"/u/project/ngarud/michaelw/Diversity-Along-Gut/ConventionalMouse/figures/evolution/snv_change_rate.png\"\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")  # Save with high resolution and tight layout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNP changes df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_change_array = []\n",
    "different_strain_threshold = 1e-4\n",
    "\n",
    "for species in species_list:\n",
    "    print(\"Processing species %s\" % (species))\n",
    "\n",
    "    highcoverage_samples = diversity_utils.calculate_highcoverage_samples(species)\n",
    "\n",
    "    if len(highcoverage_samples) == 0:\n",
    "        print(\"Species %s doesn't meet coverage requirements. Skipping to next species.\" % (species))\n",
    "        continue\n",
    "\n",
    "    haploid_samples = diversity_utils.calculate_haploid_samples(species, quick_and_dirty=True)\n",
    "    \n",
    "    if len(haploid_samples) < 2:\n",
    "        print(\"Species %s doesn't has less than 2 haploid samples. Skipping to next species\" % (species))\n",
    "        continue\n",
    "\n",
    "    print(\"%s has multiple haploid samples!\" % (species))\n",
    "    \n",
    "    intersample_change_map = calculate_intersample_changes.load_intersample_change_map(species)\n",
    "    \n",
    "    pairs = list(intersample_change_map.keys())\n",
    "\n",
    "    for pair in pairs:\n",
    "        \n",
    "        opportunities = intersample_change_map[pair]['snps'][0]\n",
    "        changes = intersample_change_map[pair]['snps'][2]\n",
    "        number_of_changes = len(changes)\n",
    "        change_rate = number_of_changes/opportunities\n",
    "\n",
    "        if change_rate > different_strain_threshold:\n",
    "            continue\n",
    "        \n",
    "        for snp in changes:\n",
    "            gene = snp[0]\n",
    "            contig = snp[1]\n",
    "            site_pos = snp[2]\n",
    "            site_type = snp[3]\n",
    "            alt_depth_1 = snp[4]\n",
    "            depth_1 = snp[5]\n",
    "            alt_depth_2 = snp[6]\n",
    "            depth_2 = snp[7]\n",
    "            freq_1 = alt_depth_1/depth_1\n",
    "            freq_2 = alt_depth_2/depth_2\n",
    "\n",
    "\n",
    "            snp_change_array.append([species, pair[0], pair[1], opportunities, change_rate, number_of_changes, gene, contig, site_pos, site_type, freq_1, freq_2, alt_depth_1, depth_1, alt_depth_2, depth_2])\n",
    "\n",
    "snp_change_df = pd.DataFrame(data = snp_change_array, columns = [\"species\", \"sample_1\", \"sample_2\", \"opportunities\", \"change_rate\", \"number_of_changes\", \"gene\", \"contig\", \"site_pos\", \"site_type\", \"freq_1\", \"freq_2\", \"alt_depth_1\", \"depth_1\", \"alt_depth_2\", \"depth_2\"])\n",
    "snp_change_df = snp_change_df.sort_values(by = [\"species\", \"sample_1\", \"sample_2\", \"contig\", \"site_pos\"])\n",
    "\n",
    "# annotate\n",
    "## Mouse\n",
    "snp_change_df[\"mouse_1\"] = snp_change_df[\"sample_1\"].apply(lambda x: sample_metadata_map[x][\"mouse\"])\n",
    "snp_change_df[\"mouse_2\"] = snp_change_df[\"sample_2\"].apply(lambda x: sample_metadata_map[x][\"mouse\"])\n",
    "\n",
    "# cage\n",
    "snp_change_df[\"cage_1\"] = snp_change_df[\"sample_1\"].apply(lambda x: sample_metadata_map[x][\"cage\"])\n",
    "snp_change_df[\"cage_2\"] = snp_change_df[\"sample_2\"].apply(lambda x: sample_metadata_map[x][\"cage\"])\n",
    "\n",
    "# cage\n",
    "snp_change_df[\"location_1\"] = snp_change_df[\"sample_1\"].apply(lambda x: sample_metadata_map[x][\"location\"])\n",
    "snp_change_df[\"location_2\"] = snp_change_df[\"sample_2\"].apply(lambda x: sample_metadata_map[x][\"location\"])\n",
    "\n",
    "# Host orientation\n",
    "snp_change_df[\"orientation\"] = snp_change_df.apply(lambda row: \"Within host\" if ((row[\"mouse_1\"] == row[\"mouse_2\"]) & (row[\"cage_1\"] == row[\"cage_2\"])) else \"Between host\", axis = 1)\n",
    "\n",
    "# Coarse graining\n",
    "snp_change_df[\"coarse_location_1\"] = snp_change_df[\"location_1\"].apply(lambda x: \"Small intestine\" if x in [\"Duodenum\", \"Jejunum\", \"Ileum\"] else \"Large intestine\")\n",
    "snp_change_df[\"coarse_location_2\"] = snp_change_df[\"location_2\"].apply(lambda x: \"Small intestine\" if x in [\"Duodenum\", \"Jejunum\", \"Ileum\"] else \"Large intestine\")\n",
    "\n",
    "# Taxnomic assignment\n",
    "\n",
    "snp_change_df['taxonomic_assignment'] = snp_change_df[\"species\"].apply(lambda x: species_code_map[x])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/u/project/ngarud/michaelw/Diversity-Along-Gut/ConventionalMouse/tables/snp_changes.tsv\"\n",
    "snp_change_df.to_csv(out_path, sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersample_change_map[('Cec_1_1','Cec_2_1')]['snps'][2][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
