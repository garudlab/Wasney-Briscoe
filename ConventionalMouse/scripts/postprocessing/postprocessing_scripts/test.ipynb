{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correcting gene name issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `core_gene_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "import config\n",
    "import gzip\n",
    "import os.path\n",
    "import os\n",
    "import midas_db_utils\n",
    "import parse_midas_data #MW: Added 09/21/23\n",
    "import species_utils\n",
    "import core_gene_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_genes_directory = (\"%score_genes/\" % config.data_directory)\n",
    "external_core_genes_directory = (\"%score_genes/external/\" % config.data_directory)\n",
    "\n",
    "default_external_shared_gene_filename = (external_core_genes_directory+\"shared_genes.txt.gz\")\n",
    "default_external_core_gene_filename = (external_core_genes_directory+\"core_genes.txt.gz\")\n",
    "default_external_stringent_core_gene_filename = (external_core_genes_directory+\"core_genes_stringent.txt.gz\")\n",
    "default_external_gene_freq_template = (external_core_genes_directory+\"%s_gene_freqs.txt.gz\")\n",
    "\n",
    "default_shared_gene_filename = (core_genes_directory+\"shared_genes.txt.gz\")\n",
    "default_core_gene_filename = (core_genes_directory+\"core_genes.txt.gz\")\n",
    "default_stringent_core_gene_filename = (core_genes_directory+\"core_genes_stringent.txt.gz\")\n",
    "default_gene_freq_template = (core_genes_directory+\"%s_gene_freqs.txt.gz\")\n",
    "\n",
    "#HMP data #MW added on 11/2/23\n",
    "shared_gene_HMP_filename = (core_genes_directory+\"shared_genes_HMP.txt.gz\")\n",
    "core_gene_HMP_filename = (core_genes_directory+\"core_genes_HMP.txt.gz\")\n",
    "stringent_core_gene_HMP_filename = (core_genes_directory+\"core_genes_stringent_HMP.txt.gz\")\n",
    "\n",
    "pangenome_species = parse_midas_data.parse_species_list() # MW 08/29/2025: loaded all species in the species_snps.txt file\n",
    "\n",
    "cmin = config.core_genome_min_copynum\n",
    "cmax = config.core_genome_max_copynum  \n",
    "shared_cmin = config.shared_genome_min_copynum\n",
    "\n",
    "min_good_fraction = config.core_genome_min_prevalence\n",
    "min_coverage = 5 # (for assessing core genome, we'll use a lower coverage value than when we look at real changes)\n",
    "\n",
    "\n",
    "species_name = \"100112\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading genes on reference genome..\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.stderr.write(\"Loading genes on reference genome..\\n\")\n",
    "reference_genes = midas_db_utils.load_reference_genes(species_name)\n",
    "sys.stderr.write(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pangenome data for 100112...\n",
      "MGBC000112_03705 gene not found in .genes file in clusters_99_info.tsv file. Appending normal gene name.\n",
      "MGBC118706_02522 gene not found in .genes file in clusters_99_info.tsv file. Appending normal gene name.\n",
      "MGBC000057_02978 gene not found in .genes file in clusters_99_info.tsv file. Appending normal gene name.\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load gene coverage information for species_name\n",
    "bad_pangenome_data = False\n",
    "sys.stderr.write(\"Loading pangenome data for %s...\\n\" % species_name)\n",
    "gene_samples, gene_names, gene_presence_matrix, gene_depth_matrix, marker_coverages, gene_reads_matrix = parse_midas_data.parse_pangenome_data(species_name)\n",
    "sys.stderr.write(\"Done!\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MGBC000057_03240\" in reference_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_coverage_idxs = (marker_coverages>=min_coverage)\n",
    "high_coverage_idxs.sum() < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = numpy.array(gene_names)\n",
    "gene_samples = gene_samples[high_coverage_idxs]\n",
    "marker_coverages = marker_coverages[high_coverage_idxs]\n",
    "gene_depth_matrix = gene_depth_matrix[:,high_coverage_idxs] \n",
    "gene_copynum_matrix = gene_depth_matrix*1.0/(marker_coverages+(marker_coverages==0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sample_idxs = core_gene_utils.get_good_pangenome_samples(species_name, marker_coverages, gene_copynum_matrix)\n",
    "bad_sample_idxs = numpy.logical_not(good_sample_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_samples = gene_samples[good_sample_idxs]\n",
    "marker_coverages = marker_coverages[good_sample_idxs]\n",
    "gene_copynum_matrix = gene_copynum_matrix[:,good_sample_idxs]\n",
    "\n",
    "reference_gene_idxs = numpy.array([gene_name in reference_genes for gene_name in gene_names]) \n",
    "# THIS MIGHT BE A PROBLEM--ONLY 708 genes \"pass\" (are in the reference genome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(reference_gene_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MY CODE ###\n",
    "non_reference_genes = numpy.array([gene_name for gene_name in gene_names if gene_name not in reference_genes]) \n",
    "\"MGBC000112_02952\" in reference_genes\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(['205567', '263040', '211853', '213184', '100334', '234341', '214912', '251524', '266763', '265132', '264624', '261649', '240066', '237892', '214845', '213999', '209914', '207693', '207550', '207450', '204195', '264289', '262170', '259253', '213942', '100555', '100375', '264714', '261672', '231109', '214603', '208232', '204819', '204699', '100042', '236627', '230525', '216453', '216392', '264455', '263672', '231258', '217378', '100600', '213583', '100158', '265345', '253991', '232356', '217253', '217094', '205224', '205142', '100320', '265282', '265025', '264958', '264316', '261755', '229722', '229547', '217744', '209106', '100111', '263323', '261676', '231887', '206400', '202897', '201916', '265152', '262018', '229998', '218434', '216954', '211235', '263558', '231977', '216689', '206896', '205270', '100500', '264599', '263490', '231995', '231118', '229914', '217610', '100113', '264501', '264045', '263510', '255975', '237711', '231349', '217240', '208519', '205132', '100110', '265440', '264450', '204380', '203686', '266183', '264298', '263303', '242035', '236833', '231504', '100338', '264454', '231066', '229633', '229275', '209838', '208766', '100395', '100171', '100118'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metagenome_shared_idxs = ((gene_copynum_matrix>shared_cmin).sum(axis=1)>0.5) # 341 shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_idxs = metagenome_shared_idxs # MW 07/09/2025: no cross_species_centroids.txt.gz\n",
    "non_shared_idxs = numpy.logical_not(shared_idxs) # 4479 non-shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idxs = (((gene_copynum_matrix>=cmin)*(gene_copynum_matrix<=cmax)).sum(axis=1)*1.0/len(marker_coverages) >= min_good_fraction) #indexes in which gene copy numbers are between 0.3 and 3 in 90% of samples (2147 good idxs)\n",
    "core_gene_idxs = good_idxs*reference_gene_idxs*non_shared_idxs\n",
    "core_gene_names = gene_names[core_gene_idxs] # only 39 genes :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(core_gene_names) # 289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"MGBC000112_02952\" in reference_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"MGBC118706_01662\" in gene_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `parse_midas_data.parse_pangenome_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "import bz2\n",
    "import gzip\n",
    "import lz4.frame\n",
    "import os.path \n",
    "import stats_utils \n",
    "from math import floor, ceil\n",
    "import gene_diversity_utils\n",
    "\n",
    "import config\n",
    "import sample_utils\n",
    "from parse_midas_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_name = \"100112\"\n",
    "allowed_samples = []\n",
    "allowed_genes=[]\n",
    "convert_centroid_names=True\n",
    "disallowed_genes=[]\n",
    "remove_c = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = config.data_directory\n",
    "analysis_directory = config.analysis_directory\n",
    "scripts_directory = config.scripts_directory\n",
    "midas_directory = config.midas_directory\n",
    "project_directory = config.project_folder #MW: added 12/15/23\n",
    "metadata_directory = config.metadata_directory #MW: added 07/30/24\n",
    "\n",
    "# We use this one to debug because it was the first one we looked at\n",
    "debug_species_name = config.debug_species_name\n",
    "\n",
    "from sample_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open post-processed MIDAS output\n",
    "# Raw read counts\n",
    "gene_reads_file =  lz4.frame.open(\"%sgenes/%s/%s.genes_reads.tsv.lz4\" % (data_directory, species_name, species_name),\"rt\", encoding = \"utf-8\") # MW 07/14/2025: decoding bytes like object\n",
    "# Depth (read counts / length?)\n",
    "gene_depth_file =  lz4.frame.open(\"%sgenes/%s/%s.genes_depth.tsv.lz4\" % (data_directory, species_name, species_name),\"rt\", encoding = \"utf-8\") # MW 07/14/2025: decoding bytes like object\n",
    "# Presence absence calls\n",
    "gene_presabs_file =  lz4.frame.open(\"%sgenes/%s/%s.genes_presabs.tsv.lz4\" % (data_directory, species_name, species_name),\"rt\", encoding = \"utf-8\") # MW 07/14/2025: decoding bytes like object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_summary_file = open(\"%sgenes/genes_summary.tsv\" % (data_directory),\"r\") # MW 07/10/2025: gene_summary.tsv file now found in genes/ folder and has all species\n",
    "marker_coverage_map = {}\n",
    "gene_summary_file.readline() # header\n",
    "marker_coverage_samples = []\n",
    "marker_coverages = []\n",
    "for summary_line in gene_summary_file:\n",
    "    items = summary_line.split() \n",
    "    sample = items[0].strip()\n",
    "    species_id = items[1].strip()\n",
    "    if species_id != species_name: # MW 07/10/2025: gene_summary.tsv has all species, so skip row that doesn't have species\n",
    "        continue\n",
    "    marker_coverage = float(items[8]) # MW 07/10/2025: gene_summary.tsv marker_depth at index 8, not 5\n",
    "    marker_coverage_samples.append(sample)\n",
    "    marker_coverages.append(marker_coverage)\n",
    "\n",
    "gene_summary_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_coverage_map = {sample: marker_coverage for sample,marker_coverage in zip(marker_coverage_samples, marker_coverages)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read through remaining files\n",
    "reads_line = gene_reads_file.readline() # header\n",
    "depth_line = gene_depth_file.readline() # header\n",
    "presabs_line = gene_presabs_file.readline() # header\n",
    "items = presabs_line.split() # header\n",
    "\n",
    "if remove_c: #MW 09/23/24: added remove_c condition\n",
    "    samples = sample_utils.parse_merged_sample_names(items[1:])\n",
    "else: \n",
    "    samples = items[1:]\n",
    "\n",
    "# ordered vector of marker coverages (guaranteed to be in same order as samples)\n",
    "marker_coverages = numpy.array([marker_coverage_map[sample] for sample in samples])\n",
    "\n",
    "if len(allowed_samples)==0:\n",
    "    allowed_samples = set(samples)\n",
    "else:\n",
    "    allowed_samples = (set(allowed_samples) & set(samples))\n",
    "    \n",
    "desired_sample_idxs = numpy.array([sample in allowed_samples for sample in samples])\n",
    "desired_samples = numpy.array(samples)[desired_sample_idxs] #MW 10/01/24: converted samples to an array (used to just be samples[desired_sample_idxs]\n",
    "\n",
    "marker_coverages = marker_coverages[desired_sample_idxs]\n",
    "gene_presence_matrix = []\n",
    "gene_reads_matrix = []\n",
    "gene_depth_matrix = []\n",
    "gene_names = []\n",
    "\n",
    "num_genes_processed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_line = gene_reads_file.readline() # header\n",
    "depth_line = gene_depth_file.readline() # header\n",
    "presabs_line = gene_presabs_file.readline() # header\n",
    "\n",
    "while reads_line!=\"\":\n",
    "    \n",
    "    # Loop through!\n",
    "    \n",
    "    items = presabs_line.split() # MW 07/09/2025: decode bytes like object\n",
    "    gene_name = items[0] \n",
    "    gene_presences = numpy.array([float(item) for item in items[1:]])[desired_sample_idxs]\n",
    "    \n",
    "    if True: #gene_presences.sum() > 0.5:\n",
    "    \n",
    "        gene_reads = numpy.array([float(item) for item in reads_line.split()[1:]])[desired_sample_idxs]\n",
    "        gene_depths = numpy.array([float(item) for item in depth_line.split()[1:]])[desired_sample_idxs]\n",
    "        \n",
    "        # Note to self: not uniform across samples!\n",
    "        #gene_lengths = gene_reads/(gene_depths+(gene_reads<0.5))\n",
    "        #print gene_lengths\n",
    "        \n",
    "        # gene is present in at least one individual! \n",
    "        gene_presence_matrix.append(gene_presences)\n",
    "        gene_depth_matrix.append(gene_depths)\n",
    "        gene_reads_matrix.append(gene_reads)\n",
    "        gene_names.append(gene_name)    \n",
    "    \n",
    "    num_genes_processed+=1\n",
    "    \n",
    "    reads_line = gene_reads_file.readline() # header\n",
    "    depth_line = gene_depth_file.readline() # header\n",
    "    presabs_line = gene_presabs_file.readline() # header\n",
    "\n",
    "gene_reads_file.close()\n",
    "gene_depth_file.close()\n",
    "gene_presabs_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convert_centroid_names:\n",
    "    new_gene_names = []\n",
    "    centroid_gene_map = load_centroid_gene_map(species_name)\n",
    "    for gene_name in gene_names:                                # MW 07/14/2025: For wahatever reason not all centroid_ids or gene_ids are in the pangemome database (accessed by load_reference_genes()), so we just attached the normal gene name if that's the case\n",
    "        if gene_name in centroid_gene_map.keys():\n",
    "            new_gene_names.append(centroid_gene_map[gene_name])\n",
    "        else: \n",
    "            sys.stderr.write(\"%s gene not found in .genes file in gene_annotations/ directory. Appending normal gene name.\\n\" % (gene_name))\n",
    "            new_gene_names.append(gene_name)\n",
    "else:\n",
    "    new_gene_names=gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_gene_map = load_centroid_gene_map(species_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_gene_map['MGBC118706_01662']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import midas_db_utils\n",
    "reference_genes = midas_db_utils.load_reference_genes(species_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"MGBC000057_03240\" in reference_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"MGBC000112_02952\" in centroid_gene_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"MGBC118706_01662\" in centroid_gene_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{key:value for key,value in centroid_gene_map.items() if key == \"MGBC118706_01662\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{key: value for key,value in centroid_gene_map.items() if value == \"MGBC118706_01662\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_presence_matrix = numpy.array(gene_presence_matrix)\n",
    "gene_depth_matrix = numpy.array(gene_depth_matrix)\n",
    "gene_reads_matrix = numpy.array(gene_reads_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pangenome_data(species_name, allowed_samples = [], allowed_genes=[], convert_centroid_names=True, disallowed_genes=[], remove_c = False): #MW 09/23/24: added remove_c condition\n",
    "    \n",
    "    if not pangenome_data_exists(species_name):\n",
    "        return [], [], [], [], [], []\n",
    "        \n",
    "    # Open post-processed MIDAS output\n",
    "    # Raw read counts\n",
    "    gene_reads_file =  lz4.frame.open(\"%sgenes/%s/%s.genes_reads.tsv.lz4\" % (data_directory, species_name, species_name),\"rt\", encoding = \"utf-8\") # MW 07/14/2025: decoding bytes like object\n",
    "    # Depth (read counts / length?)\n",
    "    gene_depth_file =  lz4.frame.open(\"%sgenes/%s/%s.genes_depth.tsv.lz4\" % (data_directory, species_name, species_name),\"rt\", encoding = \"utf-8\") # MW 07/14/2025: decoding bytes like object\n",
    "    # Presence absence calls\n",
    "    gene_presabs_file =  lz4.frame.open(\"%sgenes/%s/%s.genes_presabs.tsv.lz4\" % (data_directory, species_name, species_name),\"rt\", encoding = \"utf-8\") # MW 07/14/2025: decoding bytes like object\n",
    "    \n",
    "    # First read through gene_summary_file to get marker gene coverages\n",
    "    # Gene summary file\n",
    "    gene_summary_file = open(\"%sgenes/genes_summary.tsv\" % (data_directory),\"r\") # MW 07/10/2025: gene_summary.tsv file now found in genes/ folder and has all species\n",
    "    marker_coverage_map = {}\n",
    "    gene_summary_file.readline() # header\n",
    "    marker_coverage_samples = []\n",
    "    marker_coverages = []\n",
    "    for summary_line in gene_summary_file:\n",
    "        items = summary_line.split() \n",
    "        sample = items[0].strip()\n",
    "        species_id = items[1].strip()\n",
    "        if species_id != species_name: # MW 07/10/2025: gene_summary.tsv has all species, so skip row that doesn't have species\n",
    "            continue\n",
    "        marker_coverage = float(items[8]) # MW 07/10/2025: gene_summary.tsv marker_depth at index 8, not 5\n",
    "        marker_coverage_samples.append(sample)\n",
    "        marker_coverages.append(marker_coverage)\n",
    "\n",
    "    gene_summary_file.close()\n",
    "    \n",
    "    if remove_c: #MW 09/23/24: added remove_c condition\n",
    "        marker_coverage_samples = sample_utils.parse_merged_sample_names(marker_coverage_samples)\n",
    "\n",
    "    marker_coverage_map = {sample: marker_coverage for sample,marker_coverage in zip(marker_coverage_samples, marker_coverages)}\n",
    "    \n",
    "    # Now read through remaining files\n",
    "    reads_line = gene_reads_file.readline() # header\n",
    "    depth_line = gene_depth_file.readline() # header\n",
    "    presabs_line = gene_presabs_file.readline() # header\n",
    "    items = presabs_line.split() # header\n",
    "    \n",
    "    if remove_c: #MW 09/23/24: added remove_c condition\n",
    "        samples = sample_utils.parse_merged_sample_names(items[1:])\n",
    "    else: \n",
    "        samples = items[1:]\n",
    "    \n",
    "    # ordered vector of marker coverages (guaranteed to be in same order as samples)\n",
    "    marker_coverages = numpy.array([marker_coverage_map[sample] for sample in samples])\n",
    "    \n",
    "    if len(allowed_samples)==0:\n",
    "        allowed_samples = set(samples)\n",
    "    else:\n",
    "        allowed_samples = (set(allowed_samples) & set(samples))\n",
    "        \n",
    "    desired_sample_idxs = numpy.array([sample in allowed_samples for sample in samples])\n",
    "    desired_samples = numpy.array(samples)[desired_sample_idxs] #MW 10/01/24: converted samples to an array (used to just be samples[desired_sample_idxs]\n",
    "    \n",
    "    marker_coverages = marker_coverages[desired_sample_idxs]\n",
    "    gene_presence_matrix = []\n",
    "    gene_reads_matrix = []\n",
    "    gene_depth_matrix = []\n",
    "    gene_names = []\n",
    "    \n",
    "    num_genes_processed = 0\n",
    "    \n",
    "    reads_line = gene_reads_file.readline() # header\n",
    "    depth_line = gene_depth_file.readline() # header\n",
    "    presabs_line = gene_presabs_file.readline() # header\n",
    "    \n",
    "    while reads_line!=\"\":\n",
    "        \n",
    "        # Loop through!\n",
    "        \n",
    "        items = presabs_line.split() # MW 07/09/2025: decode bytes like object\n",
    "        gene_name = items[0] \n",
    "        gene_presences = numpy.array([float(item) for item in items[1:]])[desired_sample_idxs]\n",
    "        \n",
    "        if True: #gene_presences.sum() > 0.5:\n",
    "        \n",
    "            gene_reads = numpy.array([float(item) for item in reads_line.split()[1:]])[desired_sample_idxs]\n",
    "            gene_depths = numpy.array([float(item) for item in depth_line.split()[1:]])[desired_sample_idxs]\n",
    "            \n",
    "            # Note to self: not uniform across samples!\n",
    "            #gene_lengths = gene_reads/(gene_depths+(gene_reads<0.5))\n",
    "            #print gene_lengths\n",
    "            \n",
    "            # gene is present in at least one individual! \n",
    "            gene_presence_matrix.append(gene_presences)\n",
    "            gene_depth_matrix.append(gene_depths)\n",
    "            gene_reads_matrix.append(gene_reads)\n",
    "            gene_names.append(gene_name)    \n",
    "        \n",
    "        num_genes_processed+=1\n",
    "        \n",
    "        reads_line = gene_reads_file.readline() # header\n",
    "        depth_line = gene_depth_file.readline() # header\n",
    "        presabs_line = gene_presabs_file.readline() # header\n",
    "    \n",
    "        \n",
    "    gene_reads_file.close()\n",
    "    gene_depth_file.close()\n",
    "    gene_presabs_file.close()\n",
    "    gene_presence_matrix = numpy.array(gene_presence_matrix)\n",
    "    gene_depth_matrix = numpy.array(gene_depth_matrix)\n",
    "    gene_reads_matrix = numpy.array(gene_reads_matrix)\n",
    "\n",
    "    if convert_centroid_names:\n",
    "        new_gene_names = []\n",
    "        centroid_gene_map = load_centroid_gene_map(species_name)\n",
    "        for gene_name in gene_names:                                # MW 07/14/2025: For wahatever reason not all centroid_ids or gene_ids are in the pangemome database (accessed by load_reference_genes()), so we just attached the normal gene name if that's the case\n",
    "            if gene_name in centroid_gene_map.keys():\n",
    "                new_gene_names.append(centroid_gene_map[gene_name])\n",
    "            else: \n",
    "                sys.stderr.write(\"%s gene not found in .genes file in gene_annotations/ directory. Appending normal gene name.\\n\" % (gene_name))\n",
    "                new_gene_names.append(gene_name)\n",
    "    else:\n",
    "        new_gene_names=gene_names\n",
    "    \n",
    "    \n",
    "    new_gene_names = numpy.array(new_gene_names)\n",
    "        \n",
    "    # Now weed out disallowed genes if provided\n",
    "    disallowed_genes=set(disallowed_genes)\n",
    "    allowed_gene_idxs = []\n",
    "    for gene_idx in range(0,len(new_gene_names)):\n",
    "        \n",
    "        if new_gene_names[gene_idx] in disallowed_genes:\n",
    "            # don't include\n",
    "            pass\n",
    "        else:\n",
    "            allowed_gene_idxs.append(gene_idx)\n",
    "    allowed_gene_idxs = numpy.array(allowed_gene_idxs)\n",
    "    \n",
    "    new_gene_names = new_gene_names[allowed_gene_idxs]\n",
    "    gene_presence_matrix = gene_presence_matrix[allowed_gene_idxs,:]\n",
    "    gene_depth_matrix = gene_depth_matrix[allowed_gene_idxs,:]\n",
    "    gene_reads_matrix = gene_reads_matrix[allowed_gene_idxs,:]\n",
    "    \n",
    "    return desired_samples, new_gene_names, gene_presence_matrix, gene_depth_matrix, marker_coverages, gene_reads_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `midas_db_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import gzip\n",
    "import os\n",
    "import os.path\n",
    "import config\n",
    "import species_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_species_name = \"100112\"\n",
    "feature_file_intermediate_dir = \"%sgene_annotations/%s/\" % (config.midas_directory, desired_species_name)\n",
    "# subdir_name = os.listdir(feature_file_intermediate_dir)[0] # PROBLEM\n",
    "subdir_name = species_utils.load_reference_genome_id(desired_species_name)\n",
    "features_file = open(\"%sgene_annotations/%s/%s/%s.genes\" % (config.midas_directory, desired_species_name, subdir_name, subdir_name), 'r') \n",
    "\n",
    "features_file.readline() # header\n",
    "reference_genes = []\n",
    "for line in features_file:\n",
    "    items = line.split() \n",
    "    gene_name = items[0].strip()\n",
    "    reference_genes.append(gene_name)\n",
    "features_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the problem is that it loads the FIRST subdirectory name. This is NOT ok. We need to be pulling the reference genome (I think).\n",
    "\n",
    "so for `subdir_name` we need to get the reference genome. Let's put this into species_utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "species_name = \"100112\"\n",
    "genomes_df_path = \"%s%s\" % (config.midas_directory, \"genomes.tsv\")\n",
    "genomes_df = pd.read_csv(genomes_df_path, sep = \"\\t\")\n",
    "genomes_df[\"species\"] = genomes_df[\"species\"].astype(str)\n",
    "reference_genome_id = genomes_df.loc[(genomes_df.species == species_name) & (genomes_df.genome_is_representative == 1), \"genome\"].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_genome_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes_df.species == \"10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's wrong with `within_sample_sfs`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_midas_data\n",
    "import pylab\n",
    "import sys\n",
    "import numpy\n",
    "import bz2\n",
    "import calculate_snp_prevalences\n",
    "import diversity_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_name = \"100112\"\n",
    "debug = True\n",
    "chunk_size = 1000000000\n",
    "use_HMP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should we do this? \n",
    "sys.stderr.write(\"Loading core genes...\\n\")\n",
    "core_genes = parse_midas_data.load_core_genes(species_name)\n",
    "sys.stderr.write(\"Done! %d core genes\\n\" % len(core_genes))\n",
    "allowed_genes = core_genes\n",
    "\n",
    "sys.stderr.write(\"Loading population freqs...\\n\")\n",
    "population_freqs = calculate_snp_prevalences.parse_population_freqs(species_name, use_HMP_freqs=use_HMP) \n",
    "sys.stderr.write(\"Done! %d SNVs\\n\" % len(population_freqs))\n",
    "\n",
    "allowed_variant_type_list = ['1D','2D','3D','4D']\n",
    "allowed_variant_types = set(allowed_variant_type_list) \n",
    "\n",
    "\n",
    "# Open post-processed MIDAS output\n",
    "snp_file =  bz2.open(\"%ssnps/%s/annotated_snps.txt.bz2\" % (parse_midas_data.data_directory, species_name),\"rt\", encoding = \"utf-8\") # MW 07/10/2025: decoding bytes like object\n",
    "    \n",
    "line = snp_file.readline() # header\n",
    "items = line.split()[1:]\n",
    "samples = numpy.array([item.strip() for item in items])\n",
    "\n",
    "# We shouldn't be doing this for raw data \n",
    "#samples = parse_midas_data.parse_merged_sample_names(items)\n",
    "    \n",
    "site_map = [{} for sample in samples]\n",
    "for sample_idx in range(0,len(samples)):\n",
    "    site_map[sample_idx] = {variant_type:{} for variant_type in allowed_variant_types}\n",
    "\n",
    "sys.stderr.write(\"Calculating within-person SFSs...\\n\")        \n",
    "num_sites_processed = 0\n",
    "for line in snp_file:\n",
    "    #\n",
    "    items = line.split()\n",
    "    # Load information about site\n",
    "    info_items = items[0].split(\"|\")\n",
    "    chromosome = info_items[0]\n",
    "    location = int(info_items[1])\n",
    "    gene_name = info_items[2]\n",
    "    variant_type = info_items[3]\n",
    "    \n",
    "    if len(info_items) > 5: # for backwards compatability\n",
    "            polarization = info_items[4]\n",
    "            pvalue = float(info_items[5])\n",
    "    else: \n",
    "        polarization=\"?\"\n",
    "        pvalue = float(info_items[4])\n",
    "        \n",
    "    #    \n",
    "    if variant_type not in allowed_variant_types:\n",
    "        continue\n",
    "    #    \n",
    "    if len(allowed_genes)>0 and (gene_name not in allowed_genes):\n",
    "        continue\n",
    "    #    \n",
    "    # Load alt and depth counts\n",
    "    alts = []\n",
    "    depths = []\n",
    "    for item in items[1:]:\n",
    "        subitems = item.split(\",\")\n",
    "        alts.append(int(subitems[0]))\n",
    "        depths.append(int(subitems[1]))\n",
    "    alts = numpy.array(alts)\n",
    "    depths = numpy.array(depths)\n",
    "    refs = depths-alts\n",
    "    #print alts\n",
    "    #print depths\n",
    "    #\n",
    "    # population_freq returns the fraction of people for which the alt is the major allele.\n",
    "    # This is a very important quantity being computed! It is later used for identifying CPS samples.\n",
    "    if (chromosome, location) in population_freqs:\n",
    "        population_freq = population_freqs[(chromosome, location)]\n",
    "    else:\n",
    "        population_freq = 0\n",
    "    \n",
    "    # polarize SFS according to population freq\n",
    "    if population_freq>0.5:\n",
    "        alts,refs = refs,alts\n",
    "        population_freq = 1-population_freq\n",
    "        \n",
    "    #    \n",
    "    for i in range(0,len(alts)):\n",
    "        site = (depths[i],alts[i])\n",
    "        #\n",
    "        if site not in site_map[i][variant_type]:\n",
    "            site_map[i][variant_type][site] = [0,0.0]\n",
    "        #        \n",
    "        site_map[i][variant_type][site][0] += 1\n",
    "        site_map[i][variant_type][site][1] += population_freq # weight of polarization reversals\n",
    "        #\n",
    "        #\n",
    "    num_sites_processed+=1\n",
    "    #print num_sites_processed\n",
    "    if num_sites_processed%50000==0:\n",
    "        sys.stderr.write(\"%dk sites processed...\\n\" % (num_sites_processed/1000))   \n",
    "        if debug:\n",
    "            break\n",
    "    \n",
    "snp_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's wrong with `calculate_haploid_samples`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.linalg import eigh\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from numpy.random import shuffle, normal\n",
    "import scipy.stats\n",
    "from scipy.stats import binom\n",
    "import config\n",
    "from scipy.special import betainc\n",
    "import sys\n",
    "import parse_midas_data\n",
    "import sample_utils\n",
    "import stats_utils\n",
    "import os.path\n",
    "import sfs_utils\n",
    "from diversity_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_name = \"100112\"\n",
    "quick_and_dirty = True\n",
    "desired_samples = calculate_highcoverage_samples(species_name)\n",
    "\n",
    "samples, sfs_map = parse_midas_data.parse_within_sample_sfs(species_name, allowed_variant_types=set(['4D'])) \n",
    "\n",
    "haploid_samples = []\n",
    "for sample in desired_samples:\n",
    "    within_sites, between_sites, total_sites = sfs_utils.calculate_polymorphism_rates_from_sfs_map(sfs_map[sample])\n",
    "\n",
    "    print(\"Within sites: %s\" % (within_sites))\n",
    "    print(\"Between sites: %s\" % (between_sites))\n",
    "    print(\"Total sites: %s\" % (total_sites))\n",
    "    \n",
    "    if quick_and_dirty:\n",
    "        #QUICK AND DIRTY APPROACH: if within-sample diversity is < 1e-3, it's a haploid sample! (Mostly works)\n",
    "        if float(within_sites)/total_sites < 5e-4: # Original 1e-3\n",
    "            print(float(within_sites)/total_sites)\n",
    "            haploid_samples.append(sample)\n",
    "    else:\n",
    "        #actual approach: compare to expected number of between site differences. I use HMP panel for calculating this.\n",
    "        if within_sites <= threshold_within_between_fraction*between_sites:\n",
    "            haploid_samples.append(sample)    \n",
    "        \n",
    "# return numpy.array(haploid_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
