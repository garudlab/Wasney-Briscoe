{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/m/michaelw/.conda/envs/python_env/lib/python3.6/site-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import bz2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}') \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.axes_grid.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "import scipy.stats\n",
    "import figure_utils as fu\n",
    "from return_gene_descriptions import return_gene_descriptions\n",
    "\n",
    "from numba import njit \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import config\n",
    "import numpy\n",
    "import random as rand\n",
    "\n",
    "from random import randint,sample,choices\n",
    "from math import log\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "plasma_cmap = cm.get_cmap('plasma')\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import sys\n",
    "import os \n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.axes_grid.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "hap_cmap = ListedColormap(['grey', 'red', 'black', 'black','blue'], 'indexed')\n",
    "\n",
    "from strain_phasing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adlercreutzia_equolifaciens_60310\t Dorea_longicatena_61473\r\n",
      "Akkermansia_muciniphila_55290\t\t Enterococcus_avium_44557\r\n",
      "Alistipes_finegoldii_56071\t\t Enterococcus_faecalis_56297\r\n",
      "Alistipes_onderdonkii_55464\t\t Enterococcus_faecium_56947\r\n",
      "Alistipes_putredinis_61533\t\t Escherichia_coli_58110\r\n",
      "Alistipes_shahii_62199\t\t\t Eubacterium_cylindroides_56237\r\n",
      "Anaerostipes_hadrus_55206\t\t Eubacterium_eligens_61678\r\n",
      "Bacteroides_cellulosilyticus_58046\t Eubacterium_hallii_61477\r\n",
      "Bacteroides_finegoldii_57739\t\t Eubacterium_rectale_56927\r\n",
      "Bacteroides_fragilis_54507\t\t Faecalibacterium_cf_62236\r\n",
      "Bacteroides_massiliensis_44749\t\t Faecalibacterium_prausnitzii_57453\r\n",
      "Bacteroides_ovatus_58035\t\t Faecalibacterium_prausnitzii_61481\r\n",
      "Bacteroides_pectinophilus_61619\t\t Faecalibacterium_prausnitzii_62201\r\n",
      "Bacteroides_thetaiotaomicron_56941\t Guyana_massiliensis_60772\r\n",
      "Bacteroides_uniformis_57318\t\t Intestinimonas_butyriciproducens_60001\r\n",
      "Bacteroides_vulgatus_57955\t\t Lachnospiraceae_bacterium_51870\r\n",
      "Barnesiella_intestinihominis_62208\t Lachnospiraceae_bacterium_56833\r\n",
      "Bifidobacterium_adolescentis_56815\t Lactobacillus_acidophilus_51143\r\n",
      "Bifidobacterium_animalis_58116\t\t Lactococcus_lactis_57073\r\n",
      "Bifidobacterium_bifidum_55065\t\t Odoribacter_splanchnicus_62174\r\n",
      "Bifidobacterium_longum_57796\t\t Oscillibacter_sp_60799\r\n",
      "Bifidobacterium_pseudocatenulatum_57754  Oscillospiraceae_bacterium_54867\r\n",
      "Bilophila_wadsworthia_57364\t\t Parabacteroides_distasonis_56985\r\n",
      "Blautia_producta_56315\t\t\t Prevotella_copri_61740\r\n",
      "Blautia_wexlerae_56130\t\t\t Roseburia_hominis_61877\r\n",
      "Burkholderiales_bacterium_56577\t\t Roseburia_intestinalis_56239\r\n",
      "Clostridiales_bacterium_52743\t\t Roseburia_inulinivorans_61943\r\n",
      "Clostridiales_bacterium_52957\t\t Ruminococcus_bicirculans_59300\r\n",
      "Clostridiales_bacterium_55367\t\t Ruminococcus_bromii_62047\r\n",
      "Clostridiales_bacterium_59663\t\t Ruminococcus_gauvreauii_59033\r\n",
      "Clostridiales_bacterium_61057\t\t Ruminococcus_obeum_61472\r\n",
      "Clostridium_bolteae_57158\t\t Ruminococcus_obeum_62046\r\n",
      "Clostridium_clostridioforme_51842\t Ruminococcus_sp_55468\r\n",
      "Clostridium_hathewayi_61827\t\t Ruminococcus_sp_58571\r\n",
      "Clostridium_scindens_58238\t\t Ruminococcus_torques_62045\r\n",
      "Clostridium_sp_60465\t\t\t Streptococcus_parasanguinis_58487\r\n",
      "Clostridium_symbiosum_54029\t\t Streptococcus_salivarius_58022\r\n",
      "Coprococcus_catus_62200\t\t\t Streptococcus_salivarius_58037\r\n",
      "Coprococcus_comes_61587\t\t\t Streptococcus_thermophilus_54772\r\n",
      "Coprococcus_sp_62244\t\t\t Subdoligranulum_sp_62068\r\n",
      "Coriobacteriaceae_bacterium_58375\t Sutterella_wadsworthensis_56828\r\n",
      "Dorea_formicigenerans_56346\t\t Weissella_confusa_59158\r\n",
      "Dorea_longicatena_59913\r\n"
     ]
    }
   ],
   "source": [
    "!ls /u/project/ngarud/Garud_lab/HumanizedMouse/HumanizedMouse_Batch2/strain_phasing/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"Bacteroides_uniformis_57318\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster directory already exists.\n"
     ]
    }
   ],
   "source": [
    "strainfinder_dir = \"%sinput\" % (config.strain_phasing_directory)\n",
    "\n",
    "#Raw cluster\n",
    "raw_cluster_path = \"%s%s\" % (config.strain_phasing_directory, \"strain_clusters/\")\n",
    "species_raw_cluster_dir = \"%s%s/\" % (raw_cluster_path, species)\n",
    "if not os.path.exists(species_raw_cluster_dir):\n",
    "    os.makedirs(species_raw_cluster_dir)\n",
    "    print(\"Cluster directory created successfully!\")\n",
    "else:\n",
    "    print(\"Cluster directory already exists.\")\n",
    "species_raw_cluster_path = \"%s%s%s\" % (species_raw_cluster_dir, species, \"_RawCluster.pckl\")\n",
    "\n",
    "#Centroid and polarized cluster paths\n",
    "species_centroid_cluster_path = \"%s%s%s\" % (species_raw_cluster_dir, species, \"_ClusterCentroid.pckl\")\n",
    "species_polarized_cluster_path = \"%s%s%s\" % (species_raw_cluster_dir, species, \"_PolarizedCluster.pckl\")\n",
    "\n",
    "#FINAL Fs path\n",
    "final_Fs_path = \"%s%s%s\" % (species_raw_cluster_dir, species, \"_final_Fs.pckl\")\n",
    "\n",
    "#Evolutionary SNPs\n",
    "evo_snvs_directory = \"%sstrain_phasing/snp_changes/%s/\" % (config.project_directory, species)\n",
    "inoculum_to_mouse_changes_path = \"%s%s%s\" % (evo_snvs_directory, species,\"_inoculum_mouse_changes.pckl\")\n",
    "all_snp_changes_path = \"%s%s%s\" % (evo_snvs_directory, species,\"_all_snp_changes.pckl\")\n",
    "\n",
    "#MIDAS data\n",
    "annotated_snps_path = \"%ssnps/%s/annotated_snps.txt.bz2\" % (config.data_directory, species)\n",
    "\n",
    "# #Figure directory\n",
    "# figure_directory = \"%s%s%s\" % (config.figure_directory, \"strain_phasing/\", species)\n",
    "# if not os.path.exists(figure_directory):\n",
    "#     os.makedirs(figure_directory)\n",
    "#     print(\"Figure directory created successfully!\")\n",
    "# else:\n",
    "#     print(\"Figure directory already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Meta-parameters: experiment with these—no hard and fast rules!\n",
    "\n",
    "## minimum number of SNVs which need to be clustered together in order to qualify as a \"strain\"\n",
    "## if we didn't cap max_num_snvs, then min_cluster_size would be O(10^4), based on the typical evolutionary\n",
    "## distance between strains\n",
    "min_cluster_size = 1000\n",
    "# min_cluster_size = 50\n",
    "\n",
    "## minimum fraction of sites which pass our coverage threshold which must be in a cluster in order for it to qualify \n",
    "## as a strain\n",
    "## basically, the idea is that as the initial number of sites we pass in gets bigger, we want to incrwease the min_cluster_size\n",
    "## here, we say that 10% of all variable sites must be in a cluster in order for it to be considered a \"strain\"\n",
    "## this will largely be redundant w/ min_cluster_size, but adds some more functionality to play with\n",
    "min_cluster_fraction = 1/10\n",
    "#min_cluster_fraction = 0\n",
    "\n",
    "## For computational efficiency, we can downsample the SNVs we actually perform strain phasing on\n",
    "## should still give us the same strain trajectory \n",
    "## clustering 20k SNVs takes ~90 seconds. \n",
    "max_num_snvs = 20000\n",
    "\n",
    "## distance threshold to be considered linked—lower means trajectories have to be more \n",
    "## similar, higher means less similar, to be in a cluster\n",
    "    \n",
    "max_d = 3.5\n",
    "# max_d = 6 #USE THIS FOR B. WEXLERAE\n",
    "#max_d = 4 #USE THIS FOR B. UNIFORMIS, A. hadrus\n",
    "#max_d = 5 #Coprococcus_sp_62244\n",
    "\n",
    "\n",
    "## minimum coverage to consider allele frequency at a site for purposes of clustering\n",
    "min_coverage = 10 #MW: 20 until 6/30/2024\n",
    "# min_coverage = 5\n",
    "\n",
    "## minimum average sample coverage at polymorphic sites (e.g. sites in the A/D matrices)\n",
    "min_sample_coverage = 5\n",
    "# min_sample_coverage = 0\n",
    "\n",
    "\n",
    "## polymorphic & covered fraction: what percentage of samples does a site need \n",
    "## with coverage > min_coverage and polymorphic to be included in downstream analyses? \n",
    "## NOTE: we may want to disaggregate coverage and polymorphic-ness so as to not lose evolutionary snvs\n",
    "## but for strain clustering purposes, I think we should focus on SNVs that are actually polymorphic\n",
    "## in a good number of samples\n",
    "poly_cov_frac = 1/5 #\n",
    "\n",
    "## Number of clusters to calculate\n",
    "n_clusters = 100\n",
    "#n_clusters = 500\n",
    "\n",
    "#Minimum number of snvs per sample\n",
    "min_num_snvs_per_sample = 100\n",
    "\n",
    "#Another idea: cluster the centroids. If centroids are below a certain distance from each other, just merge. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a read support of 4 for each polymorphism.\n"
     ]
    }
   ],
   "source": [
    "Fs,Ass,Dss = return_FAD(species, min_coverage=min_coverage, \n",
    "                        min_sample_coverage=min_sample_coverage, \n",
    "                        poly_cov_frac = poly_cov_frac, \n",
    "                        calculate_poly_cov_frac=True, \n",
    "                        read_support = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out samples without an adequate number of SNVs when all is said and done\n",
    "sample_with_adequate_snv_count = ~((~np.isnan(Fs)).sum() < min_num_snvs_per_sample)\n",
    "\n",
    "Fs = Fs.loc[:,sample_with_adequate_snv_count]\n",
    "Ass = Ass.loc[:,sample_with_adequate_snv_count]\n",
    "Dss = Dss.loc[:,sample_with_adequate_snv_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying the Inoculum\n",
    "\n",
    "Fs_inoculum = Fs.loc[:,(Fs.columns.get_level_values('sample') == 'TL1gDNAshort')]\n",
    "\n",
    "Ass_inoculum = Ass.loc[:,(Ass.columns.get_level_values('sample') == 'TL1gDNAshort')]\n",
    "\n",
    "Dss_inoculum = Dss.loc[:,(Dss.columns.get_level_values('sample') == 'TL1gDNAshort')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 10321 SNVs"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 s, sys: 1.29 s, total: 29.8 s\n",
      "Wall time: 29.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "fss = Ass.values/(Dss.values + (Dss.values == 0)) #This is so it doesn't produce a na (division by 0)\n",
    "\n",
    "cluster_As = Ass.values\n",
    "cluster_Ds = Dss.values\n",
    "cluster_fs = cluster_As/(cluster_Ds + (cluster_Ds == 0))\n",
    "\n",
    "## for compatibility in case of threshold number of SNVs\n",
    "num = min(max_num_snvs,Fs.shape[0])\n",
    "\n",
    "i_list = Dss.T.mean().sort_values(ascending=False).index[:num]\n",
    "\n",
    "sys.stderr.write(\"Processing %s SNVs\" % num)\n",
    "\n",
    "## simply shuffles indices if no threshold is specified\n",
    "#i_list = sample(range(Fs.shape[0]),num)\n",
    "i_list_idx = Fs.loc[i_list].index\n",
    "\n",
    "Ass_sub = Ass.loc[i_list_idx]\n",
    "Dss_sub = Dss.loc[i_list_idx]\n",
    "Fs_sub = Fs.loc[i_list_idx]\n",
    "\n",
    "fss_sub = Ass_sub.values/(Dss_sub.values + (Dss_sub.values == 0))\n",
    "\n",
    "cluster_As_sub = Ass_sub.values\n",
    "cluster_Ds_sub = Dss_sub.values\n",
    "cluster_fs_sub = cluster_As_sub/(cluster_Ds_sub + (cluster_Ds_sub == 0))\n",
    "\n",
    "D_mat = np.zeros([num,num])\n",
    "D_mat_1 = D_mat_fun1(num,fss_sub,cluster_Ds_sub,D_mat)\n",
    "D_mat = np.zeros([num,num]) \n",
    "D_mat_2 = D_mat_fun2(num,fss_sub,cluster_Ds_sub,D_mat)\n",
    "\n",
    "D_mat = np.fmin(D_mat_1,D_mat_2) #I believe this is filling in the minimum of the two polarizations\n",
    "D_mat = symmetrize(D_mat)\n",
    "\n",
    "D_mat_1 = pd.DataFrame(D_mat_1,index=Fs_sub.index,columns=Fs_sub.index)\n",
    "D_mat_2 = pd.DataFrame(D_mat_2,index=Fs_sub.index,columns=Fs_sub.index)\n",
    "\n",
    "D_mat_close = pd.DataFrame(D_mat < max_d) \n",
    "\n",
    "D_mat_close.index = Fs_sub.index\n",
    "D_mat_close.columns = Fs_sub.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clus_idxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cfc2bb3219dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mclus_pol_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolarize_clus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclus_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclus_idxs_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_mat_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_mat_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mclus_pol_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclus_idxs_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mD_mat_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_clus_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_mat_close\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclus_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mclus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclus_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclus_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clus_idxs' is not defined"
     ]
    }
   ],
   "source": [
    "## extracts up to 100 clusters\n",
    "## in practice all SNVs should fall into one of a fairly small number of clusters\n",
    "## really should re-write this with a while loop but this works for now\n",
    "## the idea is that we exhaust all clusters—there should only be a small number of them ultimately\n",
    "\n",
    "###Idea with while loop:\n",
    "##### While there are still variants out there, have it try to be clusterings\n",
    "\n",
    "all_clus_pol = []\n",
    "all_clus_idx = []\n",
    "all_clus_A = []\n",
    "all_clus_D = []\n",
    "\n",
    "all_clus_F = []\n",
    "\n",
    "if species == \"Bacteroides_uniformis_57318\":\n",
    "    \n",
    "    clus_1,clus_idxs_1 = return_clus(D_mat_close,Fs_sub)\n",
    "    clus_pol_1 = polarize_clus(clus_1,clus_idxs_1,D_mat_1,D_mat_2)\n",
    "    clus_pol_1.index = clus_idxs_1\n",
    "    D_mat_close = drop_clus_idxs(D_mat_close,clus_idxs_1)\n",
    "    \n",
    "    clus_2,clus_idxs_2 = return_clus(D_mat_close,Fs_sub)\n",
    "    clus_pol_2 = polarize_clus(clus_2,clus_idxs_2,D_mat_1,D_mat_2)\n",
    "    clus_pol_2.index = clus_idxs_2\n",
    "    D_mat_close = drop_clus_idxs(D_mat_close,clus_idxs_2)\n",
    "    \n",
    "    clus = pd.concat([clus_1, clus_2], axis = 0)\n",
    "    clus_idxs = clus_idxs_1.append(clus_idxs_2)\n",
    "    clus_pol = pd.concat([clus_pol_1, clus_pol_2], axis = 0)\n",
    "    \n",
    "    all_clus_D.append(Dss.loc[clus.index].mean().values)\n",
    "    all_clus_pol.append(clus_pol)\n",
    "    all_clus_A.append(clus_pol.mean()*all_clus_D[-1])\n",
    "    all_clus_F.append(clus_pol.mean())\n",
    "    \n",
    "    print(clus_pol.shape[0])\n",
    "\n",
    "    \n",
    "else:\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "\n",
    "        try:\n",
    "\n",
    "            clus,clus_idxs = return_clus(D_mat_close,Fs_sub)\n",
    "    #         clus,clus_idxs = return_clus(D_mat_close,Fs_sub, co_cluster_pct=0.5) #Finding points that cluster with 25% other points. That's a cluster.\n",
    "                                                             #We would modify this function to get smaller clusters...\n",
    "            clus_pol = polarize_clus(clus,clus_idxs,D_mat_1,D_mat_2)\n",
    "            clus_pol.index = clus_idxs\n",
    "            D_mat_close = drop_clus_idxs(D_mat_close,clus_idxs)\n",
    "\n",
    "            if clus_pol.shape[0] > min_cluster_size and clus_pol.shape[0] > Fs.shape[0]*min_cluster_fraction:\n",
    "\n",
    "                all_clus_D.append(Dss.loc[clus.index].mean().values)\n",
    "                all_clus_pol.append(clus_pol)\n",
    "                all_clus_A.append(clus_pol.mean()*all_clus_D[-1])\n",
    "                all_clus_F.append(clus_pol.mean())\n",
    "\n",
    "                print(clus_pol.shape[0])\n",
    "\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## now, choosing a representative SNV from each cluster, and finding all other sites (not just limited to the 20k)\n",
    "## which are consistent w/ being linked to it\n",
    "\n",
    "final_clusters = []\n",
    "\n",
    "all_aligned_sites = []\n",
    "\n",
    "for i in range(len(all_clus_D)):\n",
    "    \n",
    "    sys.stderr.write(f'\\n\\nCluster {i+1}\\n')\n",
    "    ancD = all_clus_D[i]\n",
    "    ancF = all_clus_F[i]\n",
    "\n",
    "    dss = Dss.values\n",
    "    fss = Fs.values\n",
    "    \n",
    "    disAnc_forward = []\n",
    "    disAnc_backward = []\n",
    "\n",
    "    for j in range(Dss.shape[0]):\n",
    "        disAnc_forward.append(calc_dis(ancD,dss[j],ancF,fss[j]))\n",
    "        disAnc_backward.append(calc_dis(ancD,dss[j],ancF,1-fss[j]))\n",
    "        if j % 1000 == 0:\n",
    "            sys.stderr.write(f\"\\n\\t{np.around(100*j/Dss.shape[0],3)}% finished\")\n",
    "    \n",
    "    disAnc = [min(els) for els in zip(disAnc_forward, disAnc_backward)]\n",
    "    disAnc = np.array(disAnc)\n",
    "    aligned_sites = Fs.loc[disAnc < max_d].index\n",
    "    f_dist =  pd.DataFrame(np.array([disAnc_forward,disAnc_backward]).T,index=Fs.index)\n",
    "    pols = f_dist.T.idxmin() > 0\n",
    "    \n",
    "    aligned_sites = [a for a in aligned_sites if a not in all_aligned_sites]\n",
    "    \n",
    "    pols = pols.loc[aligned_sites]\n",
    "    re_polarize = pols.loc[pols].index\n",
    "    \n",
    "    all_aligned_sites.extend(aligned_sites)\n",
    "    \n",
    "    Fs_cluster = Fs.loc[aligned_sites]\n",
    "    \n",
    "    Fs_cluster.loc[re_polarize] = 1 - Fs_cluster.loc[re_polarize]\n",
    "        \n",
    "    final_clusters.append(Fs_cluster)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRUE for: B. uniformis\n",
    "if species == \"Bacteroides_uniformis_57318\":\n",
    "    clusters_to_merge=[0,1]\n",
    "\n",
    "    i = 0\n",
    "    while i < len(clusters_to_merge)-1:\n",
    "        final_clusters[clusters_to_merge[0]] = final_clusters[i].append(final_clusters[i+1])\n",
    "        i += 1\n",
    "\n",
    "    clusters_to_remove = clusters_to_merge[1:]\n",
    "\n",
    "    final_clusters = [final_clusters[cluster] for cluster in np.arange(len(final_clusters)) if cluster not in clusters_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING RAW FILE\n",
    "\n",
    "pickle_object = open(species_raw_cluster_path, \"wb\")\n",
    "pickle.dump(final_clusters, pickle_object)\n",
    "pickle_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LOADING THE RAW FILE\n",
    "\n",
    "final_clusters = pd.read_pickle(species_raw_cluster_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating polarized clusters\n",
    "\n",
    "Once clusters have been identified and internally polarized, they need to be polarized relative to one another. In the best case, the sum of strain frequencies will be 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cluster = False\n",
    "multiple_inoculum_strains = False\n",
    "if (len(final_clusters) == 0):\n",
    "    sys.stderr.write(\"No clusters detected.\\n\")\n",
    "    no_cluster = True\n",
    "    \n",
    "    Fs_nc,Ass_nc,Dss_nc = return_FAD(species, \n",
    "                            min_coverage=min_coverage,\n",
    "                            min_sample_coverage=min_sample_coverage,\n",
    "                            poly_cov_frac = 0, \n",
    "                            calculate_poly_cov_frac=False, \n",
    "                            read_support = False)\n",
    "    \n",
    "    if (\"Inoculum\" not in Fs_nc):\n",
    "        sys.stderr.write(\"Inoculum not in data.\\n\")\n",
    "        if Fs_nc.mean().mean() < 0.5:\n",
    "            df_final_f = 1 - Fs_nc.mean().T\n",
    "            df_final_f.loc[:,:] = 1\n",
    "            final_f = []\n",
    "            final_f.append(df_final_f)\n",
    "            final_clusters = []\n",
    "            final_clusters.append(1 - Fs_nc)\n",
    "        else:\n",
    "            df_final_f = Fs_nc.mean().T\n",
    "            df_final_f.loc[:,:] = 1\n",
    "            final_f = []\n",
    "            final_f.append(df_final_f)\n",
    "            final_clusters = []\n",
    "            final_clusters.append(Fs_nc)\n",
    "        \n",
    "    elif ((((Fs_nc > 0.0) | (Fs_nc < 1.0)) & (Ass_nc > 4)).sum()[\"Inoculum\"].values[0] > min_cluster_size):\n",
    "        #If the number of supported polymoprhic SNVs in the inoculum > 1000, infer two strains in the inoculum\n",
    "        sys.stderr.write(\"Multiple strains detected in inoculum.\\n\")\n",
    "        multiple_inoculum_strains = True\n",
    "        Fs_nc = Fs_nc.loc[:,((Dss_nc > min_coverage).sum() > min_cluster_size)]\n",
    "        Ass_nc = Ass_nc.loc[:,((Dss_nc > min_coverage).sum() > min_cluster_size)]\n",
    "        Dss_nc = Dss_nc.loc[:,((Dss_nc > min_coverage).sum() > min_cluster_size)] #Number of good coverage sites exceeds 1000\n",
    "        \n",
    "        if Fs_nc.mean().mean() < 0.5:\n",
    "            #if alleles are polarized such that the alt is < 0.5, flip the polarization\n",
    "            #extract mean using only polymorphic sites in the inoculum\n",
    "            Fs_nc = Fs_nc.loc[Fs_nc['Inoculum'][(Fs_nc['Inoculum'] > 0) & (Dss_nc['Inoculum'] > 4)].dropna().index]\n",
    "            Ass_nc = Ass_nc.loc[Fs_nc['Inoculum'][(Fs_nc['Inoculum'] > 0) & (Dss_nc['Inoculum'] > 4)].dropna().index]\n",
    "            Dss_nc = Dss_nc.loc[Fs_nc['Inoculum'][(Fs_nc['Inoculum'] > 0) & (Dss_nc['Inoculum'] > 4)].dropna().index]\n",
    "            df_final_f = 1 - Fs_nc.mean().T\n",
    "            columns_to_update = pd.DataFrame(df_final_f).T.columns.difference([('Inoculum', 'Inoculum', 'Human diet', 'Inoculum', 'TL1gDNAshort')])\n",
    "            df_final_f = pd.DataFrame(df_final_f).T\n",
    "            df_final_f.loc[:,columns_to_update] = 1\n",
    "            df_final_f = df_final_f.mean()\n",
    "            final_f = []\n",
    "            final_f.append(df_final_f)\n",
    "            final_f.append(1 - df_final_f)\n",
    "            final_clusters = []\n",
    "            final_clusters.append(1 - Fs_nc)\n",
    "            final_clusters.append(Fs_nc)\n",
    "            \n",
    "        else:\n",
    "            Fs_nc = Fs_nc.loc[Fs_nc['Inoculum'][(Fs_nc['Inoculum'] < 1) & (Dss_nc['Inoculum'] > 4)].dropna().index]\n",
    "            Ass_nc = Ass_nc.loc[Fs_nc['Inoculum'][(Fs_nc['Inoculum'] < 1) & (Dss_nc['Inoculum'] > 4)].dropna().index]\n",
    "            Dss_nc = Dss_nc.loc[Fs_nc['Inoculum'][(Fs_nc['Inoculum'] < 1) & (Dss_nc['Inoculum'] > 4)].dropna().index]\n",
    "            df_final_f = Fs_nc.mean().T\n",
    "            columns_to_update = pd.DataFrame(df_final_f).T.columns.difference([('Inoculum', 'Inoculum', 'Human diet', 'Inoculum', 'TL1gDNAshort')])\n",
    "            df_final_f = pd.DataFrame(df_final_f).T\n",
    "            df_final_f.loc[:,columns_to_update] = 1\n",
    "            df_final_f = df_final_f.mean()\n",
    "            final_f = []\n",
    "            final_f.append(df_final_f)\n",
    "            final_f.append(1-df_final_f)\n",
    "            final_clusters = []\n",
    "            final_clusters.append(Fs_nc)\n",
    "            final_clusters.append(1 - Fs_nc)\n",
    "            \n",
    "    else:\n",
    "        sys.stderr.write(\"A single strain detected in inoculum.\\n\")\n",
    "        Fs_nc = Fs_nc.loc[:,((Dss_nc > min_coverage).sum() > min_cluster_size)]\n",
    "        Ass_nc = Ass_nc.loc[:,((Dss_nc > min_coverage).sum() > min_cluster_size)]\n",
    "        Dss_nc = Dss_nc.loc[:,((Dss_nc > min_coverage).sum() > min_cluster_size)] #Number of good coverage sites exceeds 1000\n",
    "        df_final_f = Fs_nc.mean().T\n",
    "        df_final_f.loc[:,:] = 1\n",
    "        final_f = []\n",
    "        final_f.append(df_final_f)\n",
    "        if (Fs_nc.mean().mean() < 0.5): \n",
    "            #if alleles are polarized such that the alt is < 0.5, flip the polarization\n",
    "            final_clusters = []\n",
    "            final_clusters.append(1 - Fs_nc)\n",
    "        else:\n",
    "            final_clusters = []\n",
    "            final_clusters.append(Fs_nc)\n",
    "else:\n",
    "    sys.stderr.write(\"Multiple strains detected.\\n\")\n",
    "    ## If only a single cluster is detected, add a second \"cluster\" which is simply 1 minus the allele frequencies\n",
    "    ## in the first cluster\n",
    "    ## aids in visualization for people not familiar with this kind of clustering\n",
    "    if len(final_clusters) == 1:\n",
    "        final_clusters.append(1-final_clusters[0])\n",
    "    \n",
    "    ## add cluster centroids\n",
    "    final_f = []\n",
    "    for cluster in final_clusters:\n",
    "        final_f.append(cluster.mean())\n",
    "    df_final_f = pd.DataFrame(final_f)\n",
    "\n",
    "    ## now, polarize clusters so that the sum of squareds of the centroids to 1 is minimized\n",
    "    ## the idea here is that accurate strain frequencies should sum to 1\n",
    "    polarize = True\n",
    "    \n",
    "    pol_d2 = {}\n",
    "\n",
    "    for i in range(df_final_f.shape[0]):\n",
    "        df_final_f_temp = df_final_f.copy() #Makes a copy of the centroids\n",
    "        df_final_f_temp.iloc[i] = 1 - df_final_f_temp.iloc[i] #gets the polarized version of ONE of the centroids.\n",
    "        pol_d2[i] =  ((1 - df_final_f_temp.sum())**2).sum()   #Get the across centroids for all samples (should be close to 1), \n",
    "                                                                  #subtract this from 1, and square. Sum all those values\n",
    "                                                                  #Ideally, this value is really close to 0. \n",
    "                                                                  #Add this value to the dictionary.\n",
    "\n",
    "        pol_d2 = pd.Series(pol_d2)                                #Make the dictionary a series \n",
    "\n",
    "        if pol_d2.min() < ((1 - df_final_f.sum())**2).sum(): #If any of the above repolarizations actually made the overall sum of centroids closer to 1, repolarize.\n",
    "            clus_to_re_pol = pol_d2.idxmin()\n",
    "            final_f[clus_to_re_pol] = 1 - final_f[clus_to_re_pol]\n",
    "            final_clusters[clus_to_re_pol] = 1 - final_clusters[clus_to_re_pol]\n",
    "            df_final_f = pd.DataFrame(final_f)  \n",
    "            Fs_inoculum.loc[final_clusters[clus_to_re_pol].index] = 1 -  Fs_inoculum.loc[final_clusters[clus_to_re_pol].index]#polarize inoculum accordingly\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstration = True\n",
    "if demonstration:\n",
    "    final_clusters.pop(0)\n",
    "    final_f.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out samples in which each cluster does not have adequate snvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_indices = []\n",
    "\n",
    "for i,cluster in enumerate(final_clusters):\n",
    "    if i == 0:\n",
    "        good_samples = (len(final_clusters[i]) - np.isnan(final_clusters[i]).sum(axis = 0) > min_num_snvs_per_sample).values\n",
    "    else:\n",
    "        new_good_samples = (len(final_clusters[i]) - np.isnan(final_clusters[i]).sum(axis = 0) > min_num_snvs_per_sample).values\n",
    "        good_samples = good_samples & new_good_samples\n",
    "\n",
    "for i,cluster in enumerate(final_clusters): \n",
    "    final_clusters[i] = final_clusters[i].T.loc[good_samples].T\n",
    "    final_f[i] = final_f[i].T.loc[good_samples]\n",
    "if no_cluster:\n",
    "    Fs = Fs_nc.T.loc[good_samples].T\n",
    "    Ass = Ass_nc.T.loc[good_samples].T\n",
    "    Dss = Dss_nc.T.loc[good_samples].T\n",
    "else:\n",
    "    Fs = Fs.T.loc[good_samples].T\n",
    "    Ass = Ass.T.loc[good_samples].T\n",
    "    Dss = Dss.T.loc[good_samples].T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter all all na columns if there are any - THis is redundant\n",
    "if len(final_clusters) > 0:\n",
    "    for i,cluster in enumerate(final_clusters):\n",
    "        if i == 0:\n",
    "            mask = ~np.isnan(cluster).all(axis = 0)\n",
    "        final_clusters[i] = cluster.loc[:,mask]\n",
    "        final_f[i] = final_f[i][mask]\n",
    "    Fs = Fs.loc[:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#SAVING RAW FILE\n",
    "\n",
    "pickle_object = open(species_centroid_cluster_path, \"wb\")\n",
    "pickle.dump(final_f, pickle_object)\n",
    "pickle_object.close()\n",
    "\n",
    "pickle_object = open(species_polarized_cluster_path, \"wb\")\n",
    "pickle.dump(final_clusters, pickle_object)\n",
    "pickle_object.close()\n",
    "\n",
    "pickle_object = open(final_Fs_path, \"wb\")\n",
    "pickle.dump(Fs, pickle_object)\n",
    "pickle_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot the chosen polarization of strains\n",
    "## sum of strain frequencies should be ~1 at all timepoints\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(pd.DataFrame(final_f).sum().values,zorder=10,lw=3)\n",
    "ax.set_ylim([.5,1.5])\n",
    "ax.axhline(1,color=\"k\",ls=\"--\")\n",
    "ax.set_ylabel(\"Sum of strain frequencies\",size=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving versions for R plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strains = True\n",
    "bootstrap_ci = True\n",
    "boostrap_k = 100\n",
    "bootstrap_N = 1000\n",
    "if all_strains:  \n",
    "    for i in np.arange(len(final_f)): \n",
    "        if i == 0:\n",
    "            final_f_all_strains = pd.DataFrame(final_f[i]).reset_index().rename(columns = {0: \"freq\"})\n",
    "            final_f_all_strains['species'] = [species]*len(final_f_all_strains)\n",
    "            final_f_all_strains['strain'] = [i + 1]*len(final_f_all_strains)\n",
    "            final_f_all_strains = final_f_all_strains[['species','strain','mouse_number', 'region', 'diet', 'cage', 'sample', 'freq']]\n",
    "            iqr_75 = pd.DataFrame(final_clusters[i].quantile(0.75)).reset_index()\n",
    "            iqr_25 = pd.DataFrame(final_clusters[i].quantile(0.25)).reset_index()\n",
    "            final_f_all_strains = final_f_all_strains.merge(iqr_25).merge(iqr_75)\n",
    "            if bootstrap_ci:\n",
    "                upper_ci_vec = []\n",
    "                lower_ci_vec = []\n",
    "                \n",
    "                for sample_i in range(final_clusters[i].shape[1]):\n",
    "                    \n",
    "                    sample_name = final_clusters[i].iloc[:,sample_i].name[4]\n",
    "                    if  (no_cluster) & (multiple_inoculum_strains) & (sample_name != \"TL1gDNAshort\"):\n",
    "                        upper_ci_vec.append(np.nan)\n",
    "                        lower_ci_vec.append(np.nan)\n",
    "                    \n",
    "                    elif (no_cluster) & (not multiple_inoculum_strains):\n",
    "                        upper_ci_vec.append(np.nan)\n",
    "                        lower_ci_vec.append(np.nan)\n",
    "                        \n",
    "                    else:\n",
    "                        snv_freqs = final_clusters[i].iloc[:,sample_i].dropna().to_list()\n",
    "                        mean_freq_vec = []\n",
    "                        for n in range(bootstrap_N):\n",
    "                            sampled_snv_freqs = choices(snv_freqs, k = boostrap_k)\n",
    "                            mean_freq = np.mean(sampled_snv_freqs)\n",
    "                            mean_freq_vec.append(mean_freq)\n",
    "                        upper_ci = np.quantile(mean_freq_vec, 0.975)\n",
    "                        lower_ci = np.quantile(mean_freq_vec, 0.025)\n",
    "                        upper_ci_vec.append(upper_ci)\n",
    "                        lower_ci_vec.append(lower_ci)\n",
    "                    \n",
    "                \n",
    "\n",
    "        else:\n",
    "\n",
    "            final_f_all_strains_temp = pd.DataFrame(final_f[i]).reset_index().rename(columns = {0: \"freq\"})\n",
    "            final_f_all_strains_temp['species'] = [species]*len(final_f_all_strains_temp)\n",
    "            final_f_all_strains_temp['strain'] = [i + 1]*len(final_f_all_strains_temp)\n",
    "            final_f_all_strains_temp = final_f_all_strains_temp[['species','strain','mouse_number', 'region', 'diet', 'cage', 'sample', 'freq']]\n",
    "            iqr_75 = pd.DataFrame(final_clusters[i].quantile(0.75)).reset_index()\n",
    "            iqr_25 = pd.DataFrame(final_clusters[i].quantile(0.25)).reset_index()\n",
    "            final_f_all_strains_temp = final_f_all_strains_temp.merge(iqr_25).merge(iqr_75)\n",
    "            final_f_all_strains = final_f_all_strains.append(final_f_all_strains_temp, ignore_index = True)\n",
    "            if bootstrap_ci:\n",
    "                \n",
    "                for sample_i in range(final_clusters[i].shape[1]): #if we did not infer multiple strains, but there may have been multiple strains in the inoculum, just calculate CI for inoculum\n",
    "                    sample_name = final_clusters[i].iloc[:,sample_i].name[4]\n",
    "                    if  (no_cluster) & (multiple_inoculum_strains) & (sample_name != \"TL1gDNAshort\"):\n",
    "                        upper_ci_vec.append(np.nan)\n",
    "                        lower_ci_vec.append(np.nan)\n",
    "                   \n",
    "                    elif (no_cluster) & (not multiple_inoculum_strains):\n",
    "                        upper_ci_vec.append(np.nan)\n",
    "                        lower_ci_vec.append(np.nan)\n",
    "                        \n",
    "                    else:\n",
    "                        snv_freqs = final_clusters[i].iloc[:,sample_i].dropna().to_list()\n",
    "                        mean_freq_vec = []\n",
    "                        for n in range(bootstrap_N):\n",
    "                            sampled_snv_freqs = choices(snv_freqs, k = boostrap_k)\n",
    "                            mean_freq = np.mean(sampled_snv_freqs)\n",
    "                            mean_freq_vec.append(mean_freq)\n",
    "                        upper_ci = np.quantile(mean_freq_vec, 0.975)\n",
    "                        lower_ci = np.quantile(mean_freq_vec, 0.025)\n",
    "                        upper_ci_vec.append(upper_ci)\n",
    "                        lower_ci_vec.append(lower_ci)\n",
    "            \n",
    "            \n",
    "        final_f_all_strains['upper_ci'] = upper_ci_vec\n",
    "        final_f_all_strains['lower_ci'] = lower_ci_vec\n",
    "    #Renaming\n",
    "    final_f_all_strains = final_f_all_strains.rename(columns = {0.25: \"quantile_25\", 0.75: \"quantile_75\"})\n",
    "    \n",
    "    #Saving \n",
    "    \n",
    "    output_file = \"%sstrain_phasing/strain_clusters/%s/%s_strain_frequency.csv\" % (config.project_directory, species, species)\n",
    "    final_f_all_strains.to_csv(output_file, sep = \"\\t\", index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting strain frequencies\n",
    "\n",
    "Strain frequencies can be plotted using a main key (e.g. mouse_number) and a secondary key (e.g. region), yielding a two-level identification of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More ordering utilities\n",
    "mnum = list(set(Fs.T.index.get_level_values(\"mouse_number\")))\n",
    "msite = list(set(Fs.T.index.get_level_values(\"region\")))\n",
    "mdiet = list(set(Fs.T.index.get_level_values(\"diet\")))\n",
    "mcage = list(set(Fs.T.index.get_level_values(\"cage\")))\n",
    "\n",
    "mnum_sample_dic = {m:np.argwhere(reorder_sort(Fs.T,\"mouse_number\").index.get_level_values(\"mouse_number\") == m).ravel() for m in list(set(mnum))}\n",
    "\n",
    "msite_sample_dic = {m:np.argwhere(reorder_sort(Fs.T,\"region\").index.get_level_values(\"region\") == m).ravel() for m in list(set(msite))}\n",
    "\n",
    "mdiet_sample_dic = {m:np.argwhere(reorder_sort(Fs.T,\"diet\").index.get_level_values(\"diet\") == m).ravel() for m in list(set(mdiet))}\n",
    "\n",
    "mcage_sample_dic = {m:np.argwhere(reorder_sort(Fs.T,\"cage\").index.get_level_values(\"cage\") == m).ravel() for m in list(set(mcage))}\n",
    "\n",
    "all_sample_dics = {\"diet\":mdiet_sample_dic,\"region\":msite_sample_dic,\"mouse_number\":mnum_sample_dic,\"cage\":mcage_sample_dic}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blank = False\n",
    "\n",
    "key_to_sort = \"mouse_number\"\n",
    "secondary_key = \"region\"\n",
    "\n",
    "\n",
    "cmap_cage = []\n",
    "colors_library = [(1, 1, 0.8, 0.25), #creamy yellow\n",
    "                  (0.529, 0.808, 0.922, 0.25), #sky blue\n",
    "                  (0.529, 0.808, 0.922, 0.25)]\n",
    "                  #(0.529, 0.808, 0.722, 0.25), #green blue\n",
    "                  #(0.294, 0.427, 0.804, 0.15)] #purple blue\n",
    "if \"Cage 1\" in mcage_sample_dic:\n",
    "#     cmap_cage.append(colors_library(0))\n",
    "    cmap_cage.append(colors_library[0])\n",
    "if \"Cage 2\" in mcage_sample_dic:\n",
    "    cmap_cage.append(colors_library[1])\n",
    "    \n",
    "if \"Cage 3\" in mcage_sample_dic:\n",
    "    cmap_cage.append(colors_library[2])\n",
    "    \n",
    "\n",
    "cmap_clus = get_cmap(5,name=\"Set3\")\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "fig.suptitle(fu.get_pretty_species_name(species),size=30)\n",
    "\n",
    "for i,f in enumerate(final_f):\n",
    "    if blank:\n",
    "            ff = reorder_sort(f,key_to_sort).sort_index(key=lambda x: x.map(order_dict))\n",
    "    else:\n",
    "        ff = reorder_sort(f,key_to_sort).sort_index(key=lambda x: x.map(order_dict))\n",
    "        ax.plot(ff.values,zorder=100,lw=6,color=cmap_clus(i),label=f\"Strain {i+1}\");\n",
    "        ax.plot(ff.values,zorder=80,lw=7,color=\"k\");\n",
    "        if len(final_clusters) != 0:\n",
    "            ff_c = reorder_sort(final_clusters[i].T,key_to_sort).T.sort_index(key=lambda x: x.map(order_dict),axis=1)\n",
    "            ax.plot(ff_c.sample(min(ff_c.shape[0],10000)).T.values,color=cmap_clus(i),alpha=.01)\n",
    "        else:\n",
    "            for i in np.arange(len([Fs])):\n",
    "                ff_c = reorder_sort((1-Fs).T,key_to_sort).T.sort_index(key=lambda x: x.map(order_dict),axis=1)\n",
    "                ax.plot(ff_c.sample(min(ff_c.shape[0],10000)).T.values,color=cmap_clus(i),alpha=.01)\n",
    "\n",
    "\n",
    "\n",
    "# ff = reorder_sort(final_f[1],key_to_sort).sort_index(key=lambda x: x.map(order_dict))\n",
    "# ax.plot(ff.values,zorder=100,lw=6,color=cmap_clus(1),label=f\"Strain {i+1}\");\n",
    "# ax.plot(ff.values,zorder=80,lw=7,color=\"k\")\n",
    "# ff_c = reorder_sort(final_clusters[1].T,key_to_sort).T.sort_index(key=lambda x: x.map(order_dict),axis=1)\n",
    "# ax.plot(ff_c.sample(min(ff_c.shape[0],10000)).T.values,color=cmap_clus(1),alpha=.01)\n",
    "\n",
    "major_x = []\n",
    "minor_x = []\n",
    "labels = []\n",
    "\n",
    "second_xlabels = list(ff.index.get_level_values(secondary_key))\n",
    "\n",
    "\n",
    "#Making the vertical lines and labels\n",
    "i = 0\n",
    "for key, item in all_sample_dics[key_to_sort].items():\n",
    "    \n",
    "    xmin = item.min() \n",
    "    xmax = item.max()\n",
    "    \n",
    "    for e in item:\n",
    "        if key == \"Inoculum\":\n",
    "            ax.axvline(e,color=\"k\",zorder=0,alpha=1)\n",
    "        else:\n",
    "            ax.axvline(e,color=\"k\",zorder=0,alpha=.5)   \n",
    "            \n",
    "        ax.text(e, -0.1, abbreviate_gut_site(second_xlabels[e], blank_inoc = True), ha='center',va='top', clip_on=False,size=15, rotation=0)\n",
    "        \n",
    "    if xmin != xmax:\n",
    "        major_x.extend([xmin,(xmax + xmin)/2,xmax])\n",
    "        minor_x.append((xmax + xmin)/2)\n",
    "        labels.extend([\"\",key,\"\"])\n",
    "    else:\n",
    "        major_x.append(xmin)\n",
    "        minor_x.append(xmax)\n",
    "        labels.extend([key])   \n",
    "        \n",
    "    i+=1\n",
    "    \n",
    "    if (\"Inoculum\" not in all_sample_dics[key_to_sort]) & (max(all_sample_dics[key_to_sort]) == key):\n",
    "        ax.vlines(item[0] - 0.5, 0, -0.15, color='black', lw=0.8, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "        ax.vlines(item[-1] + 0.5, 0, -0.15, color='black', lw=2, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "\n",
    "    elif key == \"Inoculum\":\n",
    "        ax.vlines(item[0] - 0.5, 0, -0.15, color='black', lw=0.8, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "    else:\n",
    "        ax.vlines(item[0] - 0.5, 0, -0.15, color='black', lw=0.8, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "        ax.vlines(item[-1] + 0.5, 0, -0.15, color='black', lw=0.8, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "\n",
    "#Making the vertical colors\n",
    "key_to_sort = \"cage\"\n",
    "i = 0    \n",
    "for key, item in sorted(all_sample_dics[key_to_sort].items()):\n",
    "        \n",
    "    xmin = item.min() \n",
    "    xmax = item.max()\n",
    "        \n",
    "    if (key == max(all_sample_dics[key_to_sort])):\n",
    "        ax.vlines(item[0] - 0.5, 0, -0.15, color='black', lw=2, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "        if \"Inoculum\" != max(all_sample_dics[key_to_sort]):\n",
    "            ax.vlines(item[-1] + 0.5, 0, -0.15, color='black', lw=2, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "            ax.axvspan(xmin - .25,xmax+.25,color=cmap_cage[i]) #,alpha=.2\n",
    "        else:\n",
    "            ax.axvspan(xmin - .25,xmax+.25,alpha=.2,color='black') \n",
    "\n",
    "        i+=1\n",
    "    else:\n",
    "        ax.axvspan(xmin - .1,xmax+.1,color=cmap_cage[i]) #alpha=.2,\n",
    "        ax.vlines(item[0] - 0.5, 0, -0.15, color='black', lw=2, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "        ax.vlines(item[-1] + 0.5, 0, -0.15, color='black', lw=2, clip_on=False, transform=ax.get_xaxis_transform())\n",
    "\n",
    "        i+=1\n",
    "\n",
    "\n",
    "ax.set_xticks(major_x)\n",
    "ax.set_xticks(minor_x, minor = True)\n",
    "ax.set_xticklabels([label if label != \"Inoculum\" else \"\" for label in labels]);\n",
    "\n",
    "ax.axhline(0,color=\"grey\")\n",
    "ax.axhline(1,color=\"grey\")\n",
    "\n",
    "ax.tick_params(axis = 'x', which = 'major', length=0,labelsize = 20,pad=45)\n",
    "ax.tick_params(axis = 'x', which = 'minor', length = 10,labelsize = 0)\n",
    "    \n",
    "ax.set_ylabel(\"Strain frequency\",size=30)\n",
    "ax.set_ylim([-0.05,1.05]);\n",
    "if \"Inoculum\" in labels:\n",
    "    ax.set_xlim([-1,max(major_x)+0.25]);\n",
    "    \n",
    "\n",
    "ax.set_xlabel(\"Sample\", size = 30)\n",
    "\n",
    "\n",
    "fig.legend(prop={\"size\":20});\n",
    "# fig.legend(prop={\"size\":20}, bbox_to_anchor=(0.85, 0.5));\n",
    "\n",
    "        \n",
    "############ ADDING SFS #################\n",
    "# Create a new axis on the right side\n",
    "if (\"Inoculum\" in labels):\n",
    "\n",
    "    ax_hist = ax.inset_axes([1, 0, 0.1, 1])\n",
    "    \n",
    "    if len(final_clusters) ==0:\n",
    "        hist_data = Fs[\"Inoculum\"].dropna().values\n",
    "        ax_hist.hist(hist_data, alpha = 0.5, bins = 25, color = cmap_clus(0), orientation = \"horizontal\")\n",
    "    else:   \n",
    "        for i,final_cluster in enumerate(final_clusters):\n",
    "            hist_data = final_cluster[\"Inoculum\"].dropna().values\n",
    "            ax_hist.hist(hist_data, alpha = 0.5, bins = 25, color = cmap_clus(i), orientation = \"horizontal\")\n",
    "    \n",
    "#     final_cluster = final_clusters[1]\n",
    "#     hist_data = final_cluster[\"Inoculum\"].dropna().values\n",
    "#     ax_hist.hist(hist_data, alpha = 0.5, bins = 25, color = cmap_clus(1), orientation = \"horizontal\")\n",
    "\n",
    "#     hist_data = Fs[\"Inoculum\"].dropna().values\n",
    "#     ax_hist.hist(hist_data, alpha = 0.5, bins = 25, color = \"grey\", orientation = \"horizontal\")\n",
    "    \n",
    "    ax_hist.invert_yaxis()\n",
    "    ax_hist.set_yticks([])\n",
    "    ax_hist.set_xticks([])\n",
    "    ax_hist.set_frame_on(False)\n",
    "    ax_hist.invert_yaxis()\n",
    "\n",
    "    # Set the title for the histogram\n",
    "    ax_hist.set_xlabel(\"Inoculum\", fontsize = 20, labelpad=17.5)\n",
    "\n",
    "#plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(final_f) > 0) & (len(Fs.columns) > 0):\n",
    "\n",
    "    #Figure directory\n",
    "    figure_directory = \"%s%s%s\" % (config.figure_directory, \"strain_phasing/\", species)\n",
    "    if not os.path.exists(figure_directory):\n",
    "        os.makedirs(figure_directory)\n",
    "        print(\"Figure directory created successfully!\")\n",
    "    else:\n",
    "        print(\"Figure directory already exists.\")\n",
    "    if blank:\n",
    "        figure_path = \"%s/%s_strain_phasing_blank.png\" % (figure_directory, species)\n",
    "    else:\n",
    "        figure_path = \"%s/%s_strain_phasing_supplement.png\" % (figure_directory, species)\n",
    "    \n",
    "#     figure_path = \"%s/%s_strain_phasing_blank_nohist.png\" % (figure_directory, species)\n",
    "#     figure_path = \"%s/%s_strain_phasing_1snvcluster.png\" % (figure_directory, species)\n",
    "\n",
    "    fig.savefig(figure_path, facecolor='white', transparent=False, dpi=300,bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
